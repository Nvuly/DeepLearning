{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#사전 학습(pre-training) - 업스트림 태스크(upstream task)\n",
    "#\n",
    "#구글에서는 BERT를 학습시켜서 커뮤니티에 올림.\n",
    "#\n",
    "#우린 그걸 받아서 다운스트림 태스크에 받아다 쓰면 되는데 그걸 transfer learning, 미세 조정(fine-tuning)이라고 함.\n",
    "#\n",
    "#transfer learning은 그냥 적용하는 것. 미세 조정(fine-tuning)은 사전학습 모델을 일부 변형해서 사용하는 방법.\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace 라이브러리 - pipeline 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- transformer를 기반으로 하는 다양한 딥러닝 모델들을 공유하는 개발자 커뮤니티\n",
    "#url : https://huggingface.co/\n",
    "#\n",
    "#- pipeline() 함수\n",
    "#\n",
    "#1) transformers 라이브러리의 가장 기본적인 함수\n",
    "#2) 사전 학습된 모델과 토크나이저를 연결하여 자연어 처리에 관한 작업을 편리하게 할 수 있도록 지원\n",
    "#\n",
    "#- 사용법(예시)\n",
    "#1) pipeline 함수 실행 : summarizer = pipeline('summarization', model, tokenizer)\n",
    "#2) 문서 요약 실행 : summarizer(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\human\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## text classification\n",
    "\n",
    "### 필요한 함수 임폴트\n",
    "from transformers import pipeline, set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "### 함수 호출, 분류 모델 생성(다운로드)\n",
    "model = pipeline('text-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test data 생성\n",
    "test_data = ['Once you choose hope, anything is possible']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9992693066596985}]\n"
     ]
    }
   ],
   "source": [
    "### 감성 분석 실행\n",
    "result = model(test_data)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.748120903968811}]\n"
     ]
    }
   ],
   "source": [
    "text = input()\n",
    "result = model(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f20fb2e25d14650ab700cf4a70e7d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\human\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "### 경제 기사 긍정 또는 부정 분류 모델 생성\n",
    "\n",
    "model_name = 'ProsusAI/finbert'\n",
    "finbert = pipeline('text-classification', model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 경제 기사 텍스트 데이터 생성\n",
    "test_data = \"Investing Club: Our takes on Amazon and Apple heading into next week's earnings reports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'neutral', 'score': 0.9251992106437683}]\n"
     ]
    }
   ],
   "source": [
    "### 감성 분석 실행\n",
    "result = finbert(test_data)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940ec355f07c48aaa25e277252d9a108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2037074ca0fa47aa9634885d143fbb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/563 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1ebd02b12749029774eef0b2b06eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a703ba128548f4b01418ad97157b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec3e0ab117c4358bccf5b34d9353650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.993305504322052}, {'label': 'LABEL_0', 'score': 0.9989787340164185}]\n"
     ]
    }
   ],
   "source": [
    "### 한국어 감성 분석\n",
    "\n",
    "# 모델 생성\n",
    "model_name = 'doya/klue-sentiment-nsmc'\n",
    "kor_model = pipeline('text-classification', model=model_name)\n",
    "\n",
    "# test data 생성\n",
    "test_data = ['음악이 주가 된, 최고의 음악영화', '발연기 도저히 못보겠다 진짜 이렇게 연기를 못할거라곤 상상도 못했네']\n",
    "\n",
    "# 감성 분석 실행\n",
    "result = kor_model(test_data)\n",
    "\n",
    "# 결과 확인하기\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82170817027456db65dde15f0dda081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11dd09fe622f416ea7eec5b56274f133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b7515506f9410188cce6a714b0afff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e7a71ab82b4fe29d2975860f7224b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642fb29c7cd2457ba0dfbb204de0586a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### pipeline 함수 호출, 모델 생성(다운로드)\n",
    "\n",
    "summarizer = pipeline('summarization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 문서 요약에 사용할 텍스트 데이터 생성\n",
    "\n",
    "text_example = '''The tower is 324 meters (1,063 ft) tall, about the same height\n",
    "as an 81-storey building, and the tallest structure in Paris. Its base is square,\n",
    "measuring 125 meters (410 ft) on each side. During its construction, the Eiffel\n",
    "Tower surpassed the Washington Monument to become the tallest man-made structure\n",
    "in the world, a title it held for 41 years until the Chrysler Building in New York\n",
    "City was finished in 1930. It was the first structure to reach a height of 300 meters.\n",
    "Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is\n",
    "now taller than the Chrysler Building by 5.2 meters (17 ft). Excluding transmitters,\n",
    "the Eiffel Tower is the second tallest free-standing structure in France\n",
    "after the Millau Viaduct.'''\n",
    "\n",
    "text_sentences = '''The chief of global tech titan Samsung Electronics has remained Korea's richest stockholder as the value of shares held by the country's wealthiest 100 swelled nearly 20 percent over the past year, a corporate tracker said Wednesday.\n",
    "Samsung Electronics Executive Chairman Lee Jae-yong held stocks worth 14.7 trillion won ($11.3 billion) as of Tuesday, up about 26 percent from Dec. 29 a year earlier and the biggest among them, according to CEO Score.\n",
    "Lee, who virtually controls South Korea's top conglomerate, Samsung Group, also chalked up the largest increase of nearly 3 trillion won over the last year.\n",
    "Lee was followed by his mother and two younger sisters. His mother, Hong Ra-hee, placed second in the country's stock-rich rankings with 9.2 trillion won, followed by Boo-jin, chairwoman of Hotel Shilla, with around 7 trillion won and Seo-hyun, in charge of the Samsung Welfare Foundation, with slightly over 6 trillion won.\n",
    "The 100 wealthiest stockholders owned a combined 118.8 trillion won worth of listed shares, up 19.5 percent from a year earlier.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tower is 324 meters (1,063 ft) tall, about the same height as an 81-storey building. Its base is square, measuring 125 meters (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world.\n"
     ]
    }
   ],
   "source": [
    "### 문서 요약 실행\n",
    "result = summarizer(text_example)\n",
    "print(result[0]['summary_text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40993830b29540f29f497360b3a9b0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a31948fed748c7b3dd25cd77e72d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c736705def49d5b7f5c1ae92aa4b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f6aa358bad47ffbe00f150665c0979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e27a0c1e0b423cb73d5f1d03d8e6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d49ed1753c04b1b8e596d82e7b9b58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### pipeline 함수 호출, 모델 생성(다운로드)(2)\n",
    "model_name='facebook/bart-large-cnn'\n",
    "summarizer = pipeline('summarization', model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e0d6617a6244d99176e00c23a736c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0267eee31164089b130d475b57e58bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96aba06f6f27456794663488a96eeca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02b2a2bf9b4491bbc081b0816330cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/177k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596df20bd49f47bd97b3968958bcc9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/682k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f348646e12405d8c32f98043773c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading added_tokens.json:   0%|          | 0.00/4.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc1ec5c20ef4fbbb371877b7e8b52f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "### 한국어 문서 요약 모델 생성\n",
    "model_name = 'gogamza/kobart-summarization'\n",
    "kor_summarizer = pipeline('summarization', model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 한글 텍스트 생성\n",
    "text_sample = '''신용점수는 개인의 신용 상태를 평가하여 점수로 나타낸 것입니다. 현재 연체 및 과거 채무 상환 이력, 대출 및 보증채무 부담 정도, 신용 거래 기간, 체크카드 및 신용카드 이용 정보, 비금융정보 등을 종합적으로 판단하여 계산합니다. 예를 들어, 과거에 연체 없이 채무 상환을 잘 한 사람은 앞으로도 채무 상환을 잘해 나갈 것이라는 신뢰 정도를 점수로 표기한 것입니다.\n",
    "신용점수 제도는 신용등급제의 문제를 보완하여 2021년에 처음 도입되었습니다. 기존에는 1~10등급으로 신용등급을 나눠 평가했는데, 이는 실제 점수가 1점밖에 차이나지 않아도 등급이 갈리며 카드 발급, 대출이 거절되며 지속적인 불만이 제기었습니다. 이에 2021년 신용등급제를 폐지하고 1~1,000점까지 1점 단위로 개인의 신용을 평가하는 점수제가 도입되었습니다.\n",
    "그렇다면 개인의 신용점수는 어떻게 결정되는 걸까요? 신용점수는 금융기관이 아니라, 개인신용평가사에서 결정합니다. 공식적인 개인신용평가사는 2곳으로 나이스평가정보와 코리아크레딧뷰로가 있습니다. 두 신용평가사에서는 자체적으로 신용점수를 산출하는 항목과 비중을 정해 신용점수를 평가하기 때문에 평가사에 따라 신용점수는 상이할 수 있습니다. 세부적인 평가 기준 및 반영 비율이 궁금하다면 각 개인신용평가회사 홈페이지에서 확인할 수 있습니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개인의 신용 상태를 개인의 신용 상태를 개인의 신용 상태를 개인의 신용 상태를 개인의 신용 상태를 평가하여 점\n"
     ]
    }
   ],
   "source": [
    "### 문서 요약 실행\n",
    "result = kor_summarizer(text_sample)\n",
    "print(result[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델은 나중에 ㅎㅎ 실습해보장~\n",
    "# \n",
    "# ainize/kobart-news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HuggingFace 라이브러리 pipeline() 함수를 이용한 실습\n",
    "'''\n",
    "1) 문서 분류(text_classification)\n",
    "2) 문서 요약(text summuarization)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3) 기계독해(MRC)\n",
    "4) 문장생성(text generation)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기계 독해 (QA)\n",
    "- 묻고 답하기 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdebfae19558459a9251125c6f17d7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf1d994a73249e0b38b8b666eb013e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3d5dd8e77b41da905011ff5dd24a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726fdd4d36434f748400c503e70ed7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dfb57e2f3f7439faa3f7392128562c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### pipeline 함수 호출, 모델 생성\n",
    "\n",
    "qa = pipeline('question-answering')\n",
    "\n",
    "# qa2 = pipeline('question-answering', model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### qa에 사용할 텍스트 데이터 생성\n",
    "\n",
    "question = \"Which name is also used to describe the Amazon rainforest in English?\"\n",
    "context = \"\"\"The Amazon rainforest (Portuguese: Floresta Amazônica or Amazônia; Spanish: Selva Amazónica, Amazonía or usually Amazonia; French: Forêt amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \"Amazonas\" in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.5200247168540955, 'start': 201, 'end': 209, 'answer': 'Amazonia'}\n"
     ]
    }
   ],
   "source": [
    "### QA 실행\n",
    "\n",
    "result = qa(\n",
    "    question=question,\n",
    "    context=context\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문장 생성(text generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "### pipeline 함수 호출, 모델 생성\n",
    "generator1 = pipeline('text-generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 생성 문장 : \n",
      "{'generated_text': \"we had a sexual intercourse. she was so happy when I had a baby\\n\\nBitchy\\n\\nSo here we are now in 2010, and that's the first time she's ever been able to go out with her two best friends for a long time. Not that long after they finally reunited for their first time.\\n\\nJH and my mom were born for good. In that time of year a lot of bad things started happening, and we all knew it. For three minutes\"}\n",
      "********************************************************************************\n",
      "두번째 생성 문장 : \n",
      "{'generated_text': \"we had a sexual intercourse. she was so happy. i saw her smile and he kissed her. her. she never asked herself that question. i didn't want to know. we didn't have to talk for a couple of days. she took a few steps forward and we talked... she asked me one last question... what was the other part of the story... how was he? she took a step back and we started kissing... she began to tell me about how he had been the reason\"}\n",
      "********************************************************************************\n",
      "세번째 생성 문장 : \n",
      "{'generated_text': 'we had a sexual intercourse. she was so happy!\"\\n\\n\"You should be ashamed of yourself!\" As the second year of college she said, \"I think that in society it is hard to feel sexual. If you can get it off your chest, you\\'ve got an orgasm.\"\\n\\nAfterward, when she had turned 18 we had three more and in all we had slept on the toilet. She was about to admit that she was very embarrassed, she must have been about to vomit'}\n",
      "********************************************************************************\n",
      "네번째 생성 문장 : \n",
      "{'generated_text': \"we had a sexual intercourse. she was so happy. i can not sleep. in bed we kissed and talked about our dreams and we could sleep through our nights. a lot of times our emotions are always there. he said he was not afraid of you, he was afraid of the world and he said she loved you, she loved you. i can not sleep and she can't see or anything. i had a lot of time to do homework and i saw it all. if i was angry\"}\n"
     ]
    }
   ],
   "source": [
    "### 문장 생성하기(1) - gpt2 모델 이용\n",
    "\n",
    "# 시드 설정\n",
    "set_seed(3)\n",
    "\n",
    "# 문장 생성\n",
    "result = generator1(\n",
    "    \n",
    "    'we had a sexual intercourse. she was so happy',#입력문장\n",
    "    max_length=100,     #매개변수\n",
    "    num_return_sequences=4, #두번째 매개변수 뒤로 문장을 몇개 만들 것이냐..\n",
    ")\n",
    "\n",
    "# 결과 확인하기\n",
    "print(f'첫번째 생성 문장 : \\n{result[0]}')\n",
    "print('*'*80)\n",
    "print(f'두번째 생성 문장 : \\n{result[1]}')\n",
    "print('*'*80)\n",
    "print(f'세번째 생성 문장 : \\n{result[2]}')\n",
    "print('*'*80)\n",
    "print(f'네번째 생성 문장 : \\n{result[3]}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\human\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2Model.\n",
      "\n",
      "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rollbackTarget",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
