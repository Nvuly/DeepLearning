{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용 X 데이터의 자료형 : \n",
      "<class 'numpy.ndarray'>\n",
      "학습용 Y 데이터의 모양 : \n",
      "<class 'numpy.ndarray'>\n",
      "********************************************************************************\n",
      "학습용 X 데이터의 모양 : \n",
      "(60000, 28, 28)\n",
      "********************************************************************************\n",
      "학습용 Y 데이터의 모양 : \n",
      "(60000,)\n",
      "평가용 X 데이터의 모양 : \n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 검증용은 valid_split 비율을 정했다면 요번에는 별도로 뽑아볼 것이다.학습용에서 검증용을 뽑을 것.\n",
    "\n",
    "### mnist dataset 다운로드\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 생성된 데이터 확인\n",
    "print(f'학습용 X 데이터의 자료형 : \\n{type(X_train)}')\n",
    "\n",
    "print(f'학습용 Y 데이터의 모양 : \\n{type(y_train)}')\n",
    "\n",
    "print('*'*80)\n",
    "\n",
    "print(f'학습용 X 데이터의 모양 : \\n{X_train.shape}')\n",
    "\n",
    "print('*'*80)\n",
    "\n",
    "print(f'학습용 Y 데이터의 모양 : \\n{y_train.shape}')\n",
    "\n",
    "print(f'평가용 X 데이터의 모양 : \\n{X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "차원 변환 후 학습용 데이터의 모양 : \n",
      "(60000, 28, 28, 1)\n",
      "********************************************************************************\n",
      "차원 변환 후 평가용 데이터의 모양 : \n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "## 2차원 배열 --> 3차운 배열\n",
    "\n",
    "'''\n",
    "1. reshape((60000, 28, 28, 1)) 함수를 사용\n",
    "2. 손글씨 이미지의 모양 변경 : 2차원(28, 28) --> 3차원(28, 28, 1)\n",
    "\n",
    "'''\n",
    "\n",
    "# 자연어할 때 LSTM(RNN)의 입력을 보면 데이터수는 batch_size를 줘야 결정이 되는데\n",
    "\n",
    "# 32가 되던 64가 되던 채워지는거고 이제 나머지가 2차원으로 ...\n",
    "\n",
    "# ( N, 476, 16 ) 이거에 비해서 4차원으로 들어간다...COnv2D의 형식자체가 공식문서 참조했을 때 4차원이다.\n",
    "\n",
    "X_train = X_train.reshape((60000,28,28,1)) # 전체데이터의 수, 이미지 하나당 28,28 --> 28,28,1로 바꾼다\n",
    "\n",
    "X_test = X_test.reshape((10000, 28, 28, 1)) # 차원 하나를 늘린다고 변하지 않는다, 일종의 트릭\n",
    "\n",
    "# 결과 확인\n",
    "print(f'차원 변환 후 학습용 데이터의 모양 : \\n{X_train.shape}')\n",
    "\n",
    "print('*'*80)\n",
    "\n",
    "print(f'차원 변환 후 평가용 데이터의 모양 : \\n{X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용 X 데이터의 첫번째 이미지 픽셀의 최댓값 : 1.0, 최솟값 : 0.0\n",
      "********************************************************************************\n",
      "평가용 X 데이터의 첫번째 이미지 픽셀의 최댓값 : 1.0, 최솟값 : 0.0\n"
     ]
    }
   ],
   "source": [
    "### Scaling(normalizing) : 픽셀의 범위를 0과 1사이로 변환\n",
    "\n",
    "# 넘파이 배열이어서 255로 나눠서 reshape.\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# 결과 확인\n",
    "print(f'학습용 X 데이터의 첫번째 이미지 픽셀의 최댓값 : {np.max(X_train[0, :, :, :])}, 최솟값 : {np.min(X_train[0, :, :, :])}')\n",
    "\n",
    "print('*'*80)\n",
    "\n",
    "print(f'평가용 X 데이터의 첫번째 이미지 픽셀의 최댓값 : {np.max(X_test[0,:,:,:])}, 최솟값 : {np.min(X_test[0, :, :, :])}')\n",
    "\n",
    "# 검증용을 반드시 만들 필요는 없다.\n",
    "\n",
    "# 전처리 끝.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습용 / 검증용 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용 X 데이터의 모양 : (48000, 28, 28, 1)\n",
      "********************************************************************************\n",
      "검증용 X 데이터의 모양 : (12000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. train_test_split() 함수를 사용\n",
    "2. 학습용 데이터의 일부를 검증용 데이터로 분할\n",
    "'''\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, #validation_split=0.2 쓰면되는데.. 이렇게 쓰는 사람도 있다.\n",
    "                 random_state=0)\n",
    "\n",
    "# 결과 확인\n",
    "\n",
    "print(f'학습용 X 데이터의 모양 : {X_train.shape}')\n",
    "\n",
    "print('*'*80)\n",
    "\n",
    "print(f'검증용 X 데이터의 모양 : {X_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 생성도 2가지 방법이 있음.\n",
    "# 1. 사용자 정의 함수\n",
    "    ### 모델 생성함수 정의\n",
    "\n",
    "def create_model():\n",
    "    # 모델 구조 정의하기\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=1, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "    # 첫번째 입력받는 Conv2D는 지정해서 오류를 내지않게 막아준다.\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2)))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPool2D((2,2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "    return model\n",
    "    \n",
    "    \n",
    "# 1 모델 구조 정의\n",
    "# 2 컴파일(compile) 어떤 손실함수로 최적화할거며.. 정해져야 한다\n",
    "\n",
    "# 책에서는 Dense Layer를 두번 사용함. Dense Layer와 Dense Layer사이에 dropout을 넣는다. Dense layer를 여러번 쓸 경우.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                31370     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50186 (196.04 KB)\n",
      "Trainable params: 50186 (196.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### 모델의 구조 확인\n",
    "\n",
    "# 모델 생성 함수 호출, 모델 생성\n",
    "\n",
    "cnn = create_model()\n",
    "\n",
    "# model.summary() 함수 사용\n",
    "\n",
    "cnn.summary()\n",
    "\n",
    "# 18496은 어떻게 나오느냐..\n",
    "\n",
    "# 32*9+1*64=18496\n",
    "\n",
    "# +1은 y절편. 289필터가 64개가 있다.. 가중치의 숫자가 18496.\n",
    "\n",
    "# flatten -> Dense도 3136+1(절편)*10행 = 31370\n",
    "\n",
    "# 시드 설정을 안해서 값은 개개인마다 다 다를 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 32) dtype=float32, numpy=\n",
      "array([[[[-0.11260578, -0.04342863,  0.06048968, -0.08023157,\n",
      "           0.05573319, -0.0419383 , -0.07560243, -0.00272986,\n",
      "          -0.01465008, -0.00695013,  0.10854517,  0.0877268 ,\n",
      "          -0.02940717, -0.06140627, -0.0927071 , -0.06710476,\n",
      "           0.09425162, -0.09680038, -0.06264424, -0.09057833,\n",
      "          -0.10460521, -0.04713024,  0.04660384, -0.02962252,\n",
      "           0.0153674 ,  0.01790302, -0.12711892, -0.11004233,\n",
      "           0.09131941, -0.03114128, -0.0890002 , -0.06161647]],\n",
      "\n",
      "        [[ 0.1403913 , -0.13683458,  0.06945312, -0.06470659,\n",
      "           0.10781993,  0.03650513, -0.13418049, -0.05483297,\n",
      "           0.08053541, -0.06004925, -0.02854141, -0.07790422,\n",
      "           0.03896973,  0.08552663,  0.05045059, -0.10120746,\n",
      "           0.05116935,  0.09445591, -0.04538339,  0.02985051,\n",
      "           0.02934739,  0.10848708, -0.04143338,  0.1231889 ,\n",
      "          -0.11603731,  0.09363832, -0.02374578,  0.01091535,\n",
      "          -0.00840707,  0.04149888,  0.06950711, -0.00135773]],\n",
      "\n",
      "        [[-0.05728042,  0.10533901,  0.0660367 , -0.1138838 ,\n",
      "           0.09622474, -0.02626754,  0.1247537 , -0.06022953,\n",
      "           0.08724846, -0.06056956, -0.06419662,  0.1286553 ,\n",
      "          -0.0327775 , -0.08819337, -0.10033822, -0.08059464,\n",
      "          -0.03585281, -0.04526892, -0.13067614,  0.06207886,\n",
      "          -0.12934822, -0.01358432,  0.00811897,  0.0235959 ,\n",
      "          -0.0904831 , -0.08960017,  0.08818316, -0.13430022,\n",
      "           0.11211367, -0.04874209,  0.09776823, -0.03426421]]],\n",
      "\n",
      "\n",
      "       [[[ 0.04824159, -0.05773143,  0.09895711, -0.04307783,\n",
      "           0.08398582, -0.11190787, -0.13146333,  0.0765108 ,\n",
      "           0.01439808,  0.13925086, -0.0498907 , -0.01208006,\n",
      "          -0.07735802,  0.04135594,  0.08338523, -0.02429275,\n",
      "           0.12889116, -0.05835035,  0.08350275,  0.12839456,\n",
      "          -0.09975563, -0.09798406, -0.05190632,  0.01305845,\n",
      "           0.08786401, -0.00737795, -0.13643186, -0.08199093,\n",
      "          -0.09295444, -0.08500268,  0.03593956, -0.12181063]],\n",
      "\n",
      "        [[-0.10707726,  0.01718858, -0.04619438, -0.09311873,\n",
      "           0.00411159, -0.08334236,  0.06739143, -0.0210276 ,\n",
      "          -0.13444322,  0.03923863, -0.02592063, -0.00610556,\n",
      "          -0.10606572,  0.1108783 ,  0.00377719,  0.07803114,\n",
      "           0.07138741,  0.10596891, -0.1371171 ,  0.11700703,\n",
      "          -0.00975196,  0.06205115, -0.13589177,  0.044497  ,\n",
      "          -0.10781872,  0.10945351,  0.07685585,  0.09499304,\n",
      "           0.14100333,  0.1124361 ,  0.10593817, -0.0876979 ]],\n",
      "\n",
      "        [[ 0.09598455, -0.00678581,  0.02009733, -0.1390008 ,\n",
      "          -0.09826478,  0.00991856,  0.12542604, -0.07577562,\n",
      "          -0.08081572,  0.01233801,  0.05903463,  0.02159657,\n",
      "          -0.00125298,  0.06785375,  0.00701709,  0.00109595,\n",
      "          -0.12271671, -0.03903016,  0.09045586, -0.1244453 ,\n",
      "           0.04153439, -0.10035527,  0.13129078,  0.00829603,\n",
      "          -0.01090179, -0.08242266,  0.12546621,  0.12317349,\n",
      "          -0.00971408,  0.10656908,  0.09678185,  0.06784599]]],\n",
      "\n",
      "\n",
      "       [[[ 0.06984927, -0.10834906, -0.08799469,  0.07674731,\n",
      "          -0.05100039,  0.0818444 , -0.04260276,  0.00986502,\n",
      "          -0.14033546,  0.06188625,  0.11277275,  0.13350289,\n",
      "           0.13850968, -0.10137551,  0.12213598,  0.03482246,\n",
      "          -0.09700912, -0.09795927, -0.05736714,  0.10513362,\n",
      "           0.01737106, -0.02534363, -0.07487408,  0.05811659,\n",
      "          -0.10489123, -0.13370672, -0.07443209, -0.12585863,\n",
      "           0.02260618, -0.02248053,  0.09090595, -0.07227242]],\n",
      "\n",
      "        [[-0.13908589,  0.06319338, -0.00683264, -0.06456365,\n",
      "          -0.06385771,  0.10295981,  0.04198256,  0.07002284,\n",
      "           0.13924898, -0.08649345,  0.07515   , -0.00293095,\n",
      "           0.1139117 , -0.00408848, -0.10178559, -0.04116502,\n",
      "           0.01429419,  0.08617951,  0.11542203, -0.03417457,\n",
      "           0.02181637, -0.07109937, -0.00423412,  0.03890134,\n",
      "          -0.14090313, -0.06173339, -0.02504729, -0.13769996,\n",
      "           0.06373772, -0.04712899,  0.04183176, -0.07326267]],\n",
      "\n",
      "        [[ 0.13593028, -0.13839228,  0.07027619,  0.11315943,\n",
      "           0.10793345, -0.14016262, -0.0366983 , -0.14176235,\n",
      "          -0.1068553 , -0.08655139, -0.05275995,  0.03268638,\n",
      "          -0.05456404, -0.09382768,  0.04856063,  0.13216071,\n",
      "           0.09135439,  0.0163016 , -0.05687466, -0.05602378,\n",
      "          -0.10848837,  0.05998968,  0.00638075, -0.02696565,\n",
      "           0.11596267,  0.05821469,  0.04492567,  0.01060559,\n",
      "           0.13756262, -0.04085238, -0.11774489,  0.14091744]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 32, 64) dtype=float32, numpy=\n",
      "array([[[[-5.82706556e-02, -2.92626843e-02, -7.23856688e-02, ...,\n",
      "          -3.38030271e-02, -3.26289535e-02, -3.46655473e-02],\n",
      "         [ 6.36713281e-02,  5.16450480e-02,  9.77287441e-03, ...,\n",
      "          -3.68767194e-02,  2.53109112e-02, -2.93073468e-02],\n",
      "         [ 7.29487911e-02, -1.02247968e-02, -6.93936571e-02, ...,\n",
      "           8.19822401e-03,  3.75626907e-02,  8.13375190e-02],\n",
      "         ...,\n",
      "         [-7.45868534e-02,  3.45579982e-02, -1.01057515e-02, ...,\n",
      "           2.86652073e-02,  5.72965369e-02,  7.38636404e-03],\n",
      "         [-7.23808855e-02,  2.07748637e-02, -6.73183054e-03, ...,\n",
      "           1.75793543e-02,  8.05619135e-02, -8.04632157e-02],\n",
      "         [ 8.03303719e-03, -4.40430455e-02,  7.71629810e-03, ...,\n",
      "           7.10154548e-02,  1.95161104e-02, -3.86903882e-02]],\n",
      "\n",
      "        [[ 7.57940859e-03,  4.98038158e-02, -4.23971042e-02, ...,\n",
      "          -6.47387952e-02, -8.09544921e-02,  4.18050066e-02],\n",
      "         [ 5.97772375e-02,  7.47548565e-02,  5.30245081e-02, ...,\n",
      "           7.42969662e-03,  2.58608907e-03,  5.19956723e-02],\n",
      "         [ 6.44090399e-02,  6.31628111e-02,  5.35685495e-02, ...,\n",
      "          -1.01071000e-02,  6.60058931e-02, -7.31591135e-03],\n",
      "         ...,\n",
      "         [-4.54476699e-02,  5.13259247e-02, -6.19586706e-02, ...,\n",
      "           3.69021073e-02, -5.09044155e-02,  7.69442320e-03],\n",
      "         [ 4.52814251e-03,  2.85253525e-02,  7.58936256e-03, ...,\n",
      "          -4.38163504e-02,  6.69870451e-02,  5.19892201e-02],\n",
      "         [-3.62894163e-02,  5.60901314e-03, -1.17497444e-02, ...,\n",
      "          -2.87402086e-02, -1.44019350e-02,  2.32816562e-02]],\n",
      "\n",
      "        [[ 1.91819072e-02,  4.33836207e-02,  4.93982807e-02, ...,\n",
      "           3.22992429e-02,  6.22268990e-02,  9.49539989e-03],\n",
      "         [-4.85366583e-03,  2.07611322e-02, -6.96828589e-02, ...,\n",
      "           5.26023135e-02,  2.05326453e-02,  6.08233288e-02],\n",
      "         [ 3.81156802e-02,  2.84842402e-03,  4.97930720e-02, ...,\n",
      "           2.87503600e-02,  6.43451288e-02, -2.47976780e-02],\n",
      "         ...,\n",
      "         [ 5.79493418e-02,  7.58738741e-02, -5.91180548e-02, ...,\n",
      "          -3.67604196e-04,  7.12897256e-02,  5.89987114e-02],\n",
      "         [-6.82482123e-02,  6.84104636e-02,  2.58286223e-02, ...,\n",
      "          -5.23248129e-02, -5.22296429e-02, -4.49135303e-02],\n",
      "         [ 5.33323362e-02,  1.23436078e-02, -6.95040077e-03, ...,\n",
      "           7.37643614e-02,  7.70101324e-02,  5.32077029e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 7.96836615e-03,  8.06639269e-02, -6.35297298e-02, ...,\n",
      "          -6.93996996e-02, -4.49460968e-02, -2.04733759e-03],\n",
      "         [ 1.63000003e-02, -6.46943897e-02,  5.65789640e-04, ...,\n",
      "           8.15222040e-02, -4.73366007e-02, -4.22760658e-02],\n",
      "         [ 5.92954531e-02, -4.62953448e-02,  7.15728179e-02, ...,\n",
      "          -6.37949929e-02,  6.70566931e-02, -2.40849480e-02],\n",
      "         ...,\n",
      "         [ 4.96959463e-02,  1.93870887e-02,  7.09417090e-02, ...,\n",
      "          -4.23043370e-02, -3.60817723e-02, -3.01837921e-02],\n",
      "         [ 6.69646934e-02, -5.54825291e-02,  1.97322741e-02, ...,\n",
      "          -9.35856253e-03,  8.05594400e-02,  2.33284011e-02],\n",
      "         [-3.83266024e-02,  3.91319022e-02,  7.32155666e-02, ...,\n",
      "          -6.53891787e-02, -3.80661711e-02, -3.31462845e-02]],\n",
      "\n",
      "        [[ 5.04970551e-03, -1.21274367e-02, -6.90522790e-02, ...,\n",
      "           7.50871375e-02, -2.73487195e-02,  6.56158105e-02],\n",
      "         [ 2.66356692e-02, -2.06748843e-02,  6.06250986e-02, ...,\n",
      "          -3.91503423e-03, -1.53342634e-03,  7.38482550e-02],\n",
      "         [-3.16409022e-03,  2.45549902e-02, -1.02367774e-02, ...,\n",
      "          -4.70731482e-02, -5.73382005e-02, -6.65367842e-02],\n",
      "         ...,\n",
      "         [ 2.87360549e-02,  8.45903158e-03, -7.96222538e-02, ...,\n",
      "           6.37210906e-04,  2.56179795e-02, -6.64362162e-02],\n",
      "         [-7.17381835e-02, -4.52326946e-02, -4.06596065e-02, ...,\n",
      "           5.05571738e-02,  6.66167960e-02,  6.41766936e-03],\n",
      "         [ 6.99833259e-02,  2.79290080e-02,  1.33806095e-02, ...,\n",
      "           8.26194063e-02,  2.04448327e-02,  1.10824108e-02]],\n",
      "\n",
      "        [[-7.15971217e-02, -7.42040575e-04,  6.41402230e-02, ...,\n",
      "          -4.93192077e-02,  1.43126249e-02,  6.99081793e-02],\n",
      "         [ 7.16497973e-02,  5.90050295e-02,  3.72571126e-02, ...,\n",
      "          -2.50814557e-02, -4.10791487e-03, -8.19938630e-02],\n",
      "         [ 5.44761643e-02,  4.26906422e-02,  4.64427546e-02, ...,\n",
      "           4.17635068e-02, -6.53353184e-02, -7.78857693e-02],\n",
      "         ...,\n",
      "         [-2.70710215e-02,  7.34797493e-02, -3.57568264e-04, ...,\n",
      "          -8.25107098e-02,  3.83638367e-02,  2.07241178e-02],\n",
      "         [-4.77062687e-02,  1.15994439e-02,  3.23427096e-02, ...,\n",
      "           6.74797520e-02,  1.60729513e-02, -1.40081868e-02],\n",
      "         [ 1.00491866e-02, -6.96035847e-02,  6.58015832e-02, ...,\n",
      "           2.67834663e-02, -7.89740682e-02, -5.74105009e-02]]],\n",
      "\n",
      "\n",
      "       [[[-5.83458953e-02, -7.23577589e-02,  4.86110523e-02, ...,\n",
      "           4.79374900e-02,  8.29005018e-02,  5.66727147e-02],\n",
      "         [-2.58876681e-02,  1.23478994e-02, -9.31149721e-03, ...,\n",
      "           6.12196997e-02, -4.22603711e-02,  6.63801506e-02],\n",
      "         [ 5.00962809e-02,  1.30836368e-02,  8.83521885e-03, ...,\n",
      "          -1.88106671e-02,  6.54084310e-02,  2.26815715e-02],\n",
      "         ...,\n",
      "         [ 6.69337586e-02,  2.38039717e-02,  1.66035518e-02, ...,\n",
      "           6.58981428e-02, -5.36618046e-02, -2.74549536e-02],\n",
      "         [-6.41106591e-02,  2.92530879e-02,  5.06983474e-02, ...,\n",
      "           7.22023472e-02,  8.97280127e-03,  5.05686477e-02],\n",
      "         [-1.94856301e-02, -7.56786913e-02,  4.70177308e-02, ...,\n",
      "           4.62185964e-02, -1.89800039e-02,  5.27134165e-02]],\n",
      "\n",
      "        [[-4.26196456e-02, -7.68229961e-02, -6.59320503e-03, ...,\n",
      "          -4.24592495e-02,  3.42300758e-02,  6.42154440e-02],\n",
      "         [-7.93673396e-02, -2.29852609e-02, -4.26228046e-02, ...,\n",
      "           5.53486496e-03, -6.74149022e-02, -7.07603991e-04],\n",
      "         [-3.40959840e-02, -9.87257808e-03, -7.86996111e-02, ...,\n",
      "           4.41446900e-05,  2.85894275e-02,  1.51923895e-02],\n",
      "         ...,\n",
      "         [-3.50395851e-02, -3.30230221e-02,  5.51482663e-02, ...,\n",
      "           4.30460349e-02, -5.36336713e-02,  3.76293063e-02],\n",
      "         [ 5.94244376e-02, -4.49855737e-02,  9.68039036e-04, ...,\n",
      "          -2.04438567e-02, -6.00740127e-02,  2.47035176e-03],\n",
      "         [ 4.86989692e-02,  3.06158662e-02,  3.40598822e-03, ...,\n",
      "          -7.48738870e-02,  4.32685241e-02,  2.43466273e-02]],\n",
      "\n",
      "        [[ 6.01163581e-02,  4.85457554e-02,  2.67750397e-02, ...,\n",
      "           5.47250733e-02, -5.77816367e-02, -4.38652933e-04],\n",
      "         [ 4.03898731e-02, -1.17367283e-02, -3.68548445e-02, ...,\n",
      "          -5.52510619e-02,  3.16199884e-02, -3.11735272e-02],\n",
      "         [-4.59852815e-02, -3.26167345e-02,  4.22021225e-02, ...,\n",
      "          -2.52177119e-02, -6.80723190e-02,  8.08827952e-02],\n",
      "         ...,\n",
      "         [ 6.34295717e-02, -3.05939317e-02, -4.69020233e-02, ...,\n",
      "           2.67479196e-02, -3.77554893e-02, -7.45625719e-02],\n",
      "         [ 6.35208860e-02, -3.43745351e-02,  4.16684523e-02, ...,\n",
      "          -3.08184847e-02, -6.10476546e-02, -5.36229238e-02],\n",
      "         [ 1.68971196e-02, -6.74088821e-02,  7.65773132e-02, ...,\n",
      "           7.05947950e-02,  4.01256084e-02, -4.40097079e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'dense/kernel:0' shape=(3136, 10) dtype=float32, numpy=\n",
      "array([[ 0.03862597, -0.00163117, -0.01065667, ...,  0.02267802,\n",
      "         0.00386431,  0.02848947],\n",
      "       [ 0.01709269,  0.01320489, -0.00666773, ..., -0.0148149 ,\n",
      "         0.03110802,  0.03275632],\n",
      "       [-0.00700923, -0.03946134,  0.00786064, ...,  0.01647041,\n",
      "        -0.03460731, -0.02620514],\n",
      "       ...,\n",
      "       [-0.00219071, -0.01454403,  0.01372639, ...,  0.01569159,\n",
      "         0.02398051,  0.021992  ],\n",
      "       [-0.03524956,  0.00209815,  0.03472657, ..., -0.00811862,\n",
      "        -0.01308234, -0.0063296 ],\n",
      "       [-0.00072124, -0.03649046,  0.00105594, ...,  0.01543234,\n",
      "        -0.04211845, -0.02977131]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "### 학습이 되지 않은 모델의 가중치 확인 --> 0에 가까운 실수\n",
    "print(cnn.weights) #학습에 의해서 가중치가 변해간다..는걸 알면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model 컴파일(compile)\n",
    "#- 개념 : 손실 함수 정의 + 최적화 함수 --> 모델 완성\n",
    "#- 손실 함수 : 모델이 계산한 예측과 정답(label)을 비교하여 손실(loss)을 계산\n",
    "#- 학습 : 경사하강법 --> 손실을 최소화하는 가중치 획득\n",
    "\n",
    "#**손실 함수 외우자! ** \n",
    "#이진 분류(binary classification)\n",
    "#tf.keras.losses.BinaryCrossentrypo\n",
    "#model.compile(loss='binary_crossentropy')\n",
    "#\n",
    "#- 0일 확률이 30이고 1일 확률이 70이야\n",
    "#\n",
    "#다중분류(multi classification)\n",
    "#1. tf.keras.losses.CategoricalCrossentropy() : \n",
    "#label --> One-Hot Encoding \n",
    "#model.compile(loss='categorical_crossentropy')\n",
    "#\n",
    "#2. tf.keras.losses.SparseCategoricalCrossentropy() :\n",
    "#label --> 정수 인코딩\n",
    "#model.compile(loss='sparse_categorical_crossentropy')\n",
    "\n",
    "#최적화\n",
    "#-최적화 함수\n",
    "#1 tf.keras.optimizers.Adam(learning_rate)\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc]'))\n",
    "#2 pdf참조\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 모델 컴파일 --> 손실 함수 정의 + 가중치 최적화 방식 + 검증용 데이터 평가 방식 --> 모델 완성\n",
    "cnn.compile(loss='sparse_categorical_crossentropy', \n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From d:\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "750/750 [==============================] - 16s 18ms/step - loss: 0.2209 - accuracy: 0.9337 - val_loss: 0.0911 - val_accuracy: 0.9715\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.0650 - accuracy: 0.9804 - val_loss: 0.0650 - val_accuracy: 0.9795\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.0494 - accuracy: 0.9849 - val_loss: 0.0471 - val_accuracy: 0.9845\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.0382 - accuracy: 0.9879 - val_loss: 0.0480 - val_accuracy: 0.9845\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.0417 - val_accuracy: 0.9867\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.0384 - val_accuracy: 0.9872\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 14s 18ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0478 - val_accuracy: 0.9849\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 14s 18ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.0453 - val_accuracy: 0.9857\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.0473 - val_accuracy: 0.9872\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 14s 18ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.0490 - val_accuracy: 0.9860\n"
     ]
    }
   ],
   "source": [
    "### 모델 학습 --> LSTM과는 달리 학습의 결과물을 저장할 수 있음\n",
    "history = cnn.fit(x=X_train,\n",
    "                  y=y_train,\n",
    "                  batch_size=64,\n",
    "                  epochs=10, #학습횟수\n",
    "                  validation_data=(X_val, y_val))#데이터를 직접 넣어줄 것이다.\n",
    "\n",
    "# 과적합일어날 때 멈추고 싶을 때 callback을 하면됨. tf.keras.callbacks.EarlyStopping, patience 몇번까지 참아줄것인가, 이후 학습중지\n",
    "\n",
    "# tf.keras.callback.modelCheckpoint 저장의 조건을 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 결과 시각화(Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.callbacks.History object at 0x00000199E1F88710>\n",
      "********************************************************************************\n",
      "<class 'dict'>\n",
      "********************************************************************************\n",
      "{'loss': [0.22085817158222198, 0.06498435139656067, 0.04936377331614494, 0.03819374740123749, 0.03146269544959068, 0.025217704474925995, 0.021774256601929665, 0.017588146030902863, 0.01439313031733036, 0.012558265589177608], 'accuracy': [0.9337499737739563, 0.9804375171661377, 0.9848750233650208, 0.9878749847412109, 0.9904583096504211, 0.992104172706604, 0.9930833578109741, 0.9946041703224182, 0.995520830154419, 0.9961666464805603], 'val_loss': [0.09107349812984467, 0.06496025621891022, 0.0470648817718029, 0.04804885759949684, 0.041661586612463, 0.038420312106609344, 0.047829244285821915, 0.045342009514570236, 0.047255776822566986, 0.04899926111102104], 'val_accuracy': [0.9714999794960022, 0.9794999957084656, 0.984499990940094, 0.984499990940094, 0.9866666793823242, 0.9872499704360962, 0.9849166870117188, 0.9856666922569275, 0.9871666431427002, 0.9860000014305115]}\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "### 학습의 결과물 저장 변수 history 확인\n",
    "print(history)\n",
    "print('*'*80)\n",
    "print(type(history.history))\n",
    "print('*'*80)\n",
    "print(history.history)\n",
    "print('*'*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 학습 결과 시각화(1) - loss\n",
    "\n",
    "# plt 기본값 6.4 4.8\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "x = np.arange(1,11)\n",
    "plt.plot(x, history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(x, history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 검증용 또는 평가용 기준으로.... train_loss val_loss로 바꿔서 해볼 것 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 모델의 가중치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습된 모델의 가중치 확인\n",
      "********************************************************************************\n",
      "[<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 32) dtype=float32, numpy=\n",
      "array([[[[-0.23171295, -0.33269122,  0.0815515 , -0.25058064,\n",
      "           0.12705071, -0.3560276 , -0.46981958,  0.22596338,\n",
      "           0.24980408,  0.09272239,  0.2047006 ,  0.09335462,\n",
      "          -0.23777182,  0.00360127, -0.04466309, -0.04224636,\n",
      "           0.1888755 , -0.18645008, -0.10346709, -0.07859997,\n",
      "          -0.3247524 ,  0.1013374 , -0.02893845,  0.01417919,\n",
      "           0.34740588,  0.21467918, -0.4284646 ,  0.02259974,\n",
      "           0.13701509, -0.01297613, -0.1768984 , -0.22261864]],\n",
      "\n",
      "        [[ 0.13487864,  0.02658434,  0.0981326 , -0.44697472,\n",
      "           0.23639932, -0.09402832, -0.21463348,  0.03336183,\n",
      "           0.37515482,  0.05269046, -0.03856954, -0.04631793,\n",
      "          -0.3531006 ,  0.10729789,  0.10541303, -0.31687805,\n",
      "          -0.00535236,  0.17803192, -0.44848445,  0.16596237,\n",
      "          -0.42372695,  0.40761778, -0.02147547,  0.1487691 ,\n",
      "          -0.11692984,  0.24401696,  0.01344076,  0.22046013,\n",
      "           0.07896011,  0.1411613 ,  0.04182468, -0.18565659]],\n",
      "\n",
      "        [[-0.06445292,  0.44430843,  0.04729933, -0.30854848,\n",
      "           0.20036556,  0.03624484,  0.29310584, -0.34831578,\n",
      "           0.37850592, -0.04636753, -0.23535681,  0.14412268,\n",
      "          -0.18309681, -0.20985362, -0.27462476, -0.36939368,\n",
      "          -0.39473677, -0.0489617 , -0.41217375,  0.16564448,\n",
      "          -0.4336323 ,  0.19006035,  0.09438355,  0.05759235,\n",
      "          -0.12242044, -0.05039893,  0.23212212, -0.18689361,\n",
      "           0.11472853, -0.12705597,  0.1494411 ,  0.06120872]]],\n",
      "\n",
      "\n",
      "       [[[ 0.01398671, -0.4274866 ,  0.11020189,  0.03523571,\n",
      "           0.16402614, -0.18350871, -0.3820191 ,  0.3185788 ,\n",
      "           0.07441255,  0.31354865,  0.08129007, -0.01000687,\n",
      "          -0.11173183,  0.09695565,  0.1979189 ,  0.20995899,\n",
      "           0.2975103 , -0.13323319,  0.26045898,  0.24054554,\n",
      "           0.12601353, -0.42241442, -0.2867874 ,  0.0749421 ,\n",
      "           0.27619252,  0.09121928, -0.39578635, -0.21487905,\n",
      "          -0.08249574, -0.08283883,  0.03203439, -0.34670058]],\n",
      "\n",
      "        [[-0.0532283 ,  0.0675471 ,  0.00836044,  0.01599418,\n",
      "           0.02999379,  0.13544542,  0.18743464,  0.03431682,\n",
      "          -0.07668012,  0.1312328 ,  0.02898188,  0.00302714,\n",
      "          -0.13388771,  0.22037403,  0.07115176,  0.30989403,\n",
      "           0.17949551,  0.18971074, -0.01235663,  0.21860571,\n",
      "           0.06795426,  0.22467329, -0.1404519 ,  0.11700878,\n",
      "          -0.6474281 ,  0.3040202 ,  0.1404255 ,  0.40053803,\n",
      "           0.2023566 ,  0.27021846,  0.17921244, -0.04156656]],\n",
      "\n",
      "        [[ 0.17038697,  0.20141289,  0.04975859, -0.02516744,\n",
      "          -0.14185396,  0.20366137,  0.29650766, -0.5058214 ,\n",
      "          -0.01143689, -0.00751601,  0.05713406,  0.08600147,\n",
      "           0.09832065,  0.16963984, -0.0088008 ,  0.13068618,\n",
      "          -0.25343755,  0.00914581,  0.2209262 , -0.2460223 ,\n",
      "           0.07692719,  0.19718458,  0.2959307 ,  0.07689022,\n",
      "           0.16251285,  0.05119487,  0.25325918,  0.37607953,\n",
      "           0.04132766,  0.23042254,  0.17129835,  0.26951748]]],\n",
      "\n",
      "\n",
      "       [[[ 0.11900283, -0.14803323, -0.16491015,  0.34159634,\n",
      "          -0.22150022,  0.3154516 , -0.00452691,  0.25840607,\n",
      "          -0.49881497,  0.22775406,  0.21654555,  0.19326964,\n",
      "           0.4055592 , -0.12063957,  0.2182444 ,  0.111217  ,\n",
      "          -0.07395089, -0.06812255,  0.11492307,  0.23426417,\n",
      "           0.35125464, -0.5452061 , -0.19386314,  0.12518738,\n",
      "          -0.34814325, -0.46903008, -0.11557847, -0.52375203,\n",
      "           0.04002788, -0.07028289,  0.16558145, -0.1514862 ]],\n",
      "\n",
      "        [[-0.15596282,  0.13986757, -0.05749976,  0.20077054,\n",
      "          -0.26447743,  0.37254602,  0.24469545,  0.21908703,\n",
      "          -0.26203248, -0.11002862,  0.20947824,  0.04166628,\n",
      "           0.32252306,  0.02556268, -0.01138977,  0.02601214,\n",
      "           0.20350593,  0.19930635,  0.2978051 , -0.15111758,\n",
      "           0.25628638, -0.32069924,  0.07441144,  0.11986493,\n",
      "          -0.18123545, -0.18428108,  0.08829066, -0.20626466,\n",
      "           0.12693195, -0.02902769,  0.0920384 ,  0.13252296]],\n",
      "\n",
      "        [[ 0.20034434, -0.04505244,  0.07207115,  0.32650542,\n",
      "           0.03273051, -0.19222543,  0.07412298, -0.28467026,\n",
      "          -0.2865657 , -0.3448289 , -0.014034  ,  0.0876161 ,\n",
      "           0.08996082, -0.01950128,  0.07776313,  0.17201027,\n",
      "           0.16269574,  0.10364175,  0.08587348, -0.3891905 ,\n",
      "           0.05063772,  0.17650658,  0.15057059, -0.00270866,\n",
      "           0.40786484,  0.03925911,  0.192427  ,  0.1736353 ,\n",
      "           0.17353629,  0.06245675, -0.20729707,  0.3812668 ]]]],\n",
      "      dtype=float32)>, <tf.Variable 'conv2d/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([-0.09735002, -0.00937406, -0.08461295,  0.02927937, -0.03518739,\n",
      "       -0.03583109, -0.03710494, -0.01258122, -0.00465935, -0.00330947,\n",
      "       -0.17579849, -0.17758146,  0.03085022, -0.08420723, -0.10113584,\n",
      "       -0.05600739, -0.10091689, -0.10406199, -0.01138875, -0.04528243,\n",
      "        0.04437609, -0.02516199, -0.04073131, -0.14168431,  0.01760954,\n",
      "       -0.04121118, -0.03290093, -0.09289442, -0.12485923, -0.15028214,\n",
      "       -0.16197725,  0.00398143], dtype=float32)>, <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 32, 64) dtype=float32, numpy=\n",
      "array([[[[-0.03343406, -0.03628195, -0.05331023, ..., -0.06086352,\n",
      "           0.027864  ,  0.02165633],\n",
      "         [ 0.05224411,  0.07644514, -0.00188746, ..., -0.00064987,\n",
      "          -0.19206151,  0.06720199],\n",
      "         [ 0.0010777 ,  0.06371699, -0.03273951, ...,  0.18089515,\n",
      "           0.16779175,  0.12913318],\n",
      "         ...,\n",
      "         [-0.12913267,  0.13112587, -0.0184827 , ...,  0.1479237 ,\n",
      "           0.14607081,  0.04445297],\n",
      "         [-0.20483467,  0.05845171, -0.02713707, ...,  0.12665905,\n",
      "           0.18263994, -0.03523539],\n",
      "         [ 0.14351708, -0.17151032, -0.0946112 , ..., -0.16250733,\n",
      "          -0.27826828,  0.08965279]],\n",
      "\n",
      "        [[ 0.0674915 ,  0.04638981, -0.05528941, ..., -0.06296644,\n",
      "          -0.05317885,  0.06049735],\n",
      "         [ 0.12130453,  0.00261993, -0.08239385, ..., -0.12720586,\n",
      "          -0.23982352, -0.03636647],\n",
      "         [ 0.02821862,  0.11492424,  0.04260832, ...,  0.09190619,\n",
      "           0.14042273,  0.08364173],\n",
      "         ...,\n",
      "         [-0.03279816,  0.11820774, -0.0814735 , ...,  0.04945213,\n",
      "          -0.00942604,  0.08201481],\n",
      "         [-0.00138023,  0.02426958, -0.0449306 , ..., -0.07805781,\n",
      "           0.11298196,  0.12552583],\n",
      "         [ 0.11500855, -0.21432826, -0.1911433 , ..., -0.15075202,\n",
      "          -0.19035609, -0.03286204]],\n",
      "\n",
      "        [[ 0.00908761,  0.01565573,  0.07527169, ..., -0.10252994,\n",
      "           0.13715056, -0.04437647],\n",
      "         [-0.04027902, -0.18901747, -0.24642582, ..., -0.1427115 ,\n",
      "           0.07266104, -0.09510338],\n",
      "         [-0.02900197,  0.02400091,  0.02216708, ..., -0.00224728,\n",
      "           0.04553101, -0.01201731],\n",
      "         ...,\n",
      "         [-0.06186963,  0.12286439, -0.0598683 , ..., -0.08440351,\n",
      "           0.08784851,  0.02402868],\n",
      "         [-0.07198252,  0.05470831,  0.03063151, ..., -0.18082282,\n",
      "          -0.00875164, -0.07948063],\n",
      "         [ 0.01331892, -0.22780608, -0.09095444, ..., -0.01815009,\n",
      "           0.22704627, -0.04414251]]],\n",
      "\n",
      "\n",
      "       [[[-0.00562521,  0.02794559, -0.06932703, ..., -0.19045137,\n",
      "          -0.08597888,  0.13443173],\n",
      "         [ 0.13538586, -0.05531456, -0.01263876, ..., -0.08049926,\n",
      "          -0.28656313,  0.05675035],\n",
      "         [-0.01577606, -0.0718938 ,  0.09199152, ..., -0.13819936,\n",
      "           0.14277728,  0.04760691],\n",
      "         ...,\n",
      "         [ 0.01565894, -0.0641436 ,  0.12924702, ..., -0.13947904,\n",
      "           0.00623443,  0.09334227],\n",
      "         [-0.00404134, -0.09744216,  0.00901847, ..., -0.23079945,\n",
      "           0.09114053,  0.11893427],\n",
      "         [ 0.03273701, -0.00879042, -0.07089125, ..., -0.0837805 ,\n",
      "          -0.36532032,  0.15589179]],\n",
      "\n",
      "        [[ 0.08965405, -0.04532834, -0.09239834, ...,  0.12530766,\n",
      "           0.01421946,  0.15803085],\n",
      "         [ 0.14615451,  0.0675826 , -0.10777289, ..., -0.00357364,\n",
      "          -0.07078926, -0.05766408],\n",
      "         [ 0.04871448,  0.04496123,  0.04364676, ..., -0.09619305,\n",
      "           0.00341326, -0.01602544],\n",
      "         ...,\n",
      "         [ 0.10248206,  0.04900724, -0.06952467, ...,  0.01893279,\n",
      "           0.11700343, -0.01472746],\n",
      "         [-0.0675021 , -0.05643794, -0.04748105, ..., -0.00476575,\n",
      "           0.12783985,  0.10043086],\n",
      "         [ 0.20750265, -0.05495812, -0.27911657, ...,  0.1947336 ,\n",
      "          -0.07645977, -0.00796096]],\n",
      "\n",
      "        [[-0.1769001 ,  0.08584215,  0.08705194, ..., -0.00709801,\n",
      "          -0.0211407 , -0.04592942],\n",
      "         [ 0.03173035,  0.05944592, -0.13741088, ..., -0.04865723,\n",
      "           0.06298578, -0.06109   ],\n",
      "         [ 0.04663103,  0.10841111,  0.05022246, ...,  0.00488957,\n",
      "          -0.02010454, -0.11402534],\n",
      "         ...,\n",
      "         [-0.09096503,  0.18466662,  0.0015223 , ...,  0.00090409,\n",
      "           0.06760284, -0.02384976],\n",
      "         [-0.05213836, -0.00658011,  0.03188169, ...,  0.1646036 ,\n",
      "           0.15617186, -0.07555217],\n",
      "         [-0.2010506 , -0.13794446, -0.1161828 , ...,  0.10718607,\n",
      "          -0.13317205, -0.1918292 ]]],\n",
      "\n",
      "\n",
      "       [[[-0.0671282 , -0.08396839, -0.07031174, ...,  0.02910905,\n",
      "          -0.04146467,  0.14128484],\n",
      "         [-0.07285068,  0.17050739,  0.05683043, ...,  0.11687847,\n",
      "          -0.1200351 ,  0.12080807],\n",
      "         [ 0.0543972 , -0.12213711, -0.05244695, ..., -0.0653761 ,\n",
      "           0.07308915,  0.09648594],\n",
      "         ...,\n",
      "         [ 0.07116479, -0.05958059, -0.0346814 , ...,  0.05834487,\n",
      "          -0.11568298,  0.04295328],\n",
      "         [-0.08912722, -0.10285351,  0.00331075, ...,  0.10361779,\n",
      "          -0.04379541,  0.09435274],\n",
      "         [-0.0592385 ,  0.11066239, -0.08018768, ...,  0.17817077,\n",
      "          -0.34460315,  0.14869604]],\n",
      "\n",
      "        [[ 0.10874783, -0.10700444, -0.14034106, ..., -0.01591446,\n",
      "          -0.11629345, -0.0460967 ],\n",
      "         [-0.08566693,  0.06706912, -0.12348608, ...,  0.11179896,\n",
      "          -0.05537789, -0.2546667 ],\n",
      "         [ 0.02148325, -0.12340114, -0.14744686, ...,  0.02941035,\n",
      "           0.05854721,  0.00953394],\n",
      "         ...,\n",
      "         [ 0.05210091, -0.1504645 ,  0.02770579, ...,  0.08398236,\n",
      "          -0.07017819, -0.07704348],\n",
      "         [ 0.08945966, -0.02632894, -0.08292767, ...,  0.06902701,\n",
      "          -0.07078259,  0.03903934],\n",
      "         [ 0.053752  ,  0.02355818, -0.17364389, ..., -0.03534016,\n",
      "          -0.14692524, -0.11259298]],\n",
      "\n",
      "        [[ 0.09610143,  0.14792392, -0.01593993, ..., -0.04166414,\n",
      "          -0.30084506, -0.18658651],\n",
      "         [-0.06986739,  0.05584155, -0.08389059, ..., -0.11146366,\n",
      "          -0.18116327, -0.08892962],\n",
      "         [-0.01667779,  0.04452518, -0.02756918, ..., -0.01067536,\n",
      "          -0.1292642 , -0.06304321],\n",
      "         ...,\n",
      "         [ 0.16571549,  0.08499093, -0.0951587 , ..., -0.00141564,\n",
      "          -0.215538  , -0.31992134],\n",
      "         [ 0.14278525,  0.0350306 , -0.04477438, ..., -0.00312482,\n",
      "          -0.17338823, -0.2479481 ],\n",
      "         [-0.1890088 , -0.03914747,  0.09719742, ..., -0.09316774,\n",
      "          -0.24227016, -0.1048262 ]]]], dtype=float32)>, <tf.Variable 'conv2d_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([-4.91304472e-02, -8.32259580e-02, -6.03638552e-02, -1.07669756e-01,\n",
      "       -8.73428732e-02, -1.06247798e-01, -1.34753019e-01, -5.89125231e-02,\n",
      "       -9.94327888e-02, -1.48421735e-01, -1.77519590e-01,  4.43698131e-02,\n",
      "       -2.24017158e-01, -5.39276153e-02, -6.55046552e-02, -1.76629931e-01,\n",
      "       -8.07430372e-02, -1.32534103e-02, -2.00334769e-02, -9.95964557e-02,\n",
      "       -2.01164782e-02, -2.63911486e-01, -3.93863767e-02, -1.74214125e-01,\n",
      "       -4.44102809e-02, -1.76076628e-02, -7.60812312e-02, -1.03450485e-01,\n",
      "       -8.87771919e-02,  3.71619277e-02, -8.34526718e-02, -8.67076144e-02,\n",
      "       -1.25103956e-02, -9.21419170e-03, -3.48102190e-02, -1.15778916e-01,\n",
      "       -1.17711619e-01, -7.82143921e-02, -4.98817563e-02, -5.82899787e-02,\n",
      "       -1.37923181e-01, -3.87682091e-03, -1.99345369e-02, -7.11986795e-02,\n",
      "        1.94627512e-02, -3.03800963e-02, -1.76602930e-01, -4.40818854e-02,\n",
      "        1.61431991e-02,  2.44489238e-02, -9.35557261e-02, -1.58613980e-01,\n",
      "       -5.87518401e-02, -8.09787586e-02, -8.24607760e-02, -6.60714954e-02,\n",
      "       -5.45167215e-02, -2.17572153e-02, -6.83394521e-02,  2.35376632e-04,\n",
      "       -4.19399217e-02, -6.97730109e-02,  2.75359675e-02,  4.20468785e-02],\n",
      "      dtype=float32)>, <tf.Variable 'dense/kernel:0' shape=(3136, 10) dtype=float32, numpy=\n",
      "array([[ 2.73640305e-02,  5.30953296e-02, -9.86876525e-03, ...,\n",
      "         3.43939178e-02, -3.50353755e-02,  1.13638816e-02],\n",
      "       [-6.55380562e-02,  3.31482179e-02, -1.98037066e-02, ...,\n",
      "        -1.83988586e-02,  4.59998101e-02,  3.01582403e-02],\n",
      "       [ 8.02883655e-02,  7.70674273e-02, -1.16777875e-01, ...,\n",
      "         6.68443143e-02, -3.24110053e-02, -1.05113849e-01],\n",
      "       ...,\n",
      "       [ 9.07228738e-02,  1.85031928e-02, -3.46811377e-02, ...,\n",
      "        -2.05382392e-01, -1.25190588e-02, -3.54772528e-05],\n",
      "       [ 3.97927426e-02, -1.00236066e-01, -3.80865969e-02, ...,\n",
      "        -1.51160836e-01,  9.43046659e-02,  1.32389246e-02],\n",
      "       [-8.27897117e-02, -1.55691594e-01, -8.47675875e-02, ...,\n",
      "        -1.97626036e-02,  3.72949615e-02, -3.87307070e-02]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=\n",
      "array([ 0.02876035,  0.07353434,  0.01262302, -0.02974832, -0.04300226,\n",
      "        0.01607123, -0.02179012,  0.00680557, -0.01912719, -0.00755494],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print('학습된 모델의 가중치 확인')\n",
    "\n",
    "print('*'*80)\n",
    "\n",
    "print(cnn.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0397 - accuracy: 0.9884\n",
      "평가용 데이터에 대한 성능 평가 : \n",
      "[0.039730899035930634, 0.9883999824523926]\n"
     ]
    }
   ],
   "source": [
    "## 평가용 데이터에 대한 성능 평가\n",
    "result = cnn.evaluate(X_test, y_test, batch_size=100)\n",
    "\n",
    "# 결과 확인하기\n",
    "print(f'평가용 데이터에 대한 성능 평가 : \\n{result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.32941176]\n",
      "  [0.7254902 ]\n",
      "  [0.62352941]\n",
      "  [0.59215686]\n",
      "  [0.23529412]\n",
      "  [0.14117647]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.87058824]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.94509804]\n",
      "  [0.77647059]\n",
      "  [0.77647059]\n",
      "  [0.77647059]\n",
      "  [0.77647059]\n",
      "  [0.77647059]\n",
      "  [0.77647059]\n",
      "  [0.77647059]\n",
      "  [0.77647059]\n",
      "  [0.66666667]\n",
      "  [0.20392157]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.2627451 ]\n",
      "  [0.44705882]\n",
      "  [0.28235294]\n",
      "  [0.44705882]\n",
      "  [0.63921569]\n",
      "  [0.89019608]\n",
      "  [0.99607843]\n",
      "  [0.88235294]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.98039216]\n",
      "  [0.89803922]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.54901961]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.06666667]\n",
      "  [0.25882353]\n",
      "  [0.05490196]\n",
      "  [0.2627451 ]\n",
      "  [0.2627451 ]\n",
      "  [0.2627451 ]\n",
      "  [0.23137255]\n",
      "  [0.08235294]\n",
      "  [0.9254902 ]\n",
      "  [0.99607843]\n",
      "  [0.41568627]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.3254902 ]\n",
      "  [0.99215686]\n",
      "  [0.81960784]\n",
      "  [0.07058824]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.08627451]\n",
      "  [0.91372549]\n",
      "  [1.        ]\n",
      "  [0.3254902 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.50588235]\n",
      "  [0.99607843]\n",
      "  [0.93333333]\n",
      "  [0.17254902]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.23137255]\n",
      "  [0.97647059]\n",
      "  [0.99607843]\n",
      "  [0.24313725]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.52156863]\n",
      "  [0.99607843]\n",
      "  [0.73333333]\n",
      "  [0.01960784]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.03529412]\n",
      "  [0.80392157]\n",
      "  [0.97254902]\n",
      "  [0.22745098]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.49411765]\n",
      "  [0.99607843]\n",
      "  [0.71372549]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.29411765]\n",
      "  [0.98431373]\n",
      "  [0.94117647]\n",
      "  [0.22352941]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.0745098 ]\n",
      "  [0.86666667]\n",
      "  [0.99607843]\n",
      "  [0.65098039]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.01176471]\n",
      "  [0.79607843]\n",
      "  [0.99607843]\n",
      "  [0.85882353]\n",
      "  [0.1372549 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.14901961]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.30196078]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.12156863]\n",
      "  [0.87843137]\n",
      "  [0.99607843]\n",
      "  [0.45098039]\n",
      "  [0.00392157]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.52156863]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.20392157]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.23921569]\n",
      "  [0.94901961]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.20392157]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.4745098 ]\n",
      "  [0.99607843]\n",
      "  [0.99607843]\n",
      "  [0.85882353]\n",
      "  [0.15686275]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.4745098 ]\n",
      "  [0.99607843]\n",
      "  [0.81176471]\n",
      "  [0.07058824]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 평가용 데이터의 레이블 : \n",
      "7\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "### 첫번째 평가용 데이터에 대한 예측\n",
    "\n",
    "# 정답 확인\n",
    "sample = X_test[0, :, :, :]\n",
    "print(sample)\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.show()\n",
    "#원본 이미지를 볼 수 있는데,\n",
    "print(f'0번째 평가용 데이터의 레이블 : \\n{y_test[0]}')\n",
    "\n",
    "print('*'*80)\n",
    "\n",
    "# 예측 : model.predict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 모델을 이용한 이미지 분류 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VGG16 모델을 이용한 이미지 분류 실습\n",
    "#\n",
    "#모델소개\n",
    "#1. 개요 : 옥스포드 대학의 연구팀 VGG에 의해 개발된 이미지 분류용 모델\n",
    "#2. 구조 : Conv2D layer 13개 + MaxPooling2D layer 5개, Flatten layer 1개 + Dense layer 3개\n",
    "#Maxpooling과 Flatten layer에는 가중치가 없으므로 앞뒤로 더해서 VGG16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#재구성 모델 생성\n",
    "#- 모델 생성의 두번째 방법 : 입력 layer와 출력 layer를 지정해 줌으로써 모델을 만들 수 있음\n",
    "#1) tf.keras.Model(inputs, outputs)\n",
    "#2) 예시\n",
    "#inputs = tf.keras.Input(shape=(3,))\n",
    "#outputs = tf.keras.layers.Dense(4, activation='relu', activation='softmax')(inputs)\n",
    "#model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 증식을 이용하여 이미지 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성의 두번째 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16 (64.00 Byte)\n",
      "Trainable params: 16 (64.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "### 모델 생성의 첫번째 방법\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2d()\n",
    ".\n",
    ".\n",
    ".\n",
    ")\n",
    "'''\n",
    "\n",
    "'''\n",
    "### 모델 생성의 두번째 방법\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "'''\n",
    "\n",
    "# 입력 생성용 전용 함수\n",
    "inputs = tf.keras.Input(shape=(3,))\n",
    "\n",
    "# 출력 생성\n",
    "outputs = tf.keras.layers.Dense(units=4, activation='softmax')(inputs)\n",
    "\n",
    "# 모델 생성\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# 결과 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138357544 (527.79 MB)\n",
      "Trainable params: 138357544 (527.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### 기본 모델 생성하기\n",
    "base_model = tf.keras.applications.vgg16.VGG16(weights=None)\n",
    "\n",
    "# 모델 구조 확인\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32, numpy=\n",
      "array([[[[-0.01293196,  0.07554924,  0.06906249, ..., -0.09669562,\n",
      "           0.0968949 , -0.08149113],\n",
      "         [-0.04271078, -0.06040556,  0.08886071, ..., -0.06426936,\n",
      "          -0.01738299, -0.0861212 ],\n",
      "         [-0.03063621, -0.09639561,  0.05552842, ..., -0.02195161,\n",
      "          -0.08044682,  0.0224385 ]],\n",
      "\n",
      "        [[ 0.08931153, -0.08480199, -0.01275868, ...,  0.06124412,\n",
      "           0.05698743, -0.04129397],\n",
      "         [ 0.0700593 , -0.01983468,  0.04208343, ..., -0.01981637,\n",
      "           0.01318612,  0.01422506],\n",
      "         [-0.03302768,  0.01159646,  0.02333844, ...,  0.07898745,\n",
      "          -0.02694569,  0.03692177]],\n",
      "\n",
      "        [[-0.03096806, -0.09970168,  0.00207112, ...,  0.07431741,\n",
      "          -0.07535889, -0.02570151],\n",
      "         [ 0.03784327,  0.0619231 ,  0.07069398, ...,  0.02858008,\n",
      "          -0.01893231,  0.00098992],\n",
      "         [ 0.0913859 ,  0.04029334,  0.09918173, ..., -0.05946849,\n",
      "          -0.08974729, -0.05774982]]],\n",
      "\n",
      "\n",
      "       [[[-0.05587476,  0.05510041,  0.08160469, ..., -0.0892206 ,\n",
      "          -0.03664877, -0.08690968],\n",
      "         [ 0.04190211,  0.04016811,  0.03791314, ..., -0.01096097,\n",
      "          -0.04709815,  0.03884615],\n",
      "         [ 0.08419161, -0.07286489, -0.07588394, ...,  0.01189902,\n",
      "          -0.01387731,  0.02944101]],\n",
      "\n",
      "        [[-0.07965408,  0.0251791 , -0.0034491 , ..., -0.05607004,\n",
      "          -0.02943091,  0.0663294 ],\n",
      "         [ 0.03276089,  0.00349429, -0.0211699 , ..., -0.06924144,\n",
      "           0.08338155, -0.08338214],\n",
      "         [-0.06601231, -0.04212293,  0.02840079, ..., -0.01195065,\n",
      "          -0.07448113,  0.09526804]],\n",
      "\n",
      "        [[-0.0587728 ,  0.00524596,  0.0243547 , ...,  0.08672513,\n",
      "          -0.01839919, -0.05518348],\n",
      "         [ 0.09031639,  0.0048345 ,  0.00716407, ..., -0.06475459,\n",
      "           0.08641793,  0.01642204],\n",
      "         [-0.03603476, -0.0567789 ,  0.03892723, ..., -0.03835676,\n",
      "          -0.00955054, -0.03498159]]],\n",
      "\n",
      "\n",
      "       [[[ 0.06286581, -0.00174665, -0.06593359, ..., -0.00034913,\n",
      "           0.08263879,  0.04570882],\n",
      "         [ 0.05499946,  0.02763905, -0.03126114, ...,  0.05629234,\n",
      "          -0.03400264,  0.00369494],\n",
      "         [ 0.04105228,  0.09670034, -0.08504725, ..., -0.0992038 ,\n",
      "          -0.03093672, -0.00260166]],\n",
      "\n",
      "        [[-0.09128214,  0.02854799, -0.06194241, ...,  0.04231949,\n",
      "           0.06647354, -0.08654317],\n",
      "         [ 0.00834822,  0.06664844, -0.09825706, ...,  0.04695061,\n",
      "          -0.026506  , -0.01684377],\n",
      "         [-0.00940438, -0.07465595, -0.03342739, ..., -0.04144192,\n",
      "           0.03616102, -0.06686538]],\n",
      "\n",
      "        [[-0.03911475,  0.07128681, -0.00665122, ..., -0.08580767,\n",
      "          -0.08503957, -0.01701698],\n",
      "         [ 0.03580026,  0.07308671,  0.06331722, ..., -0.06894507,\n",
      "          -0.00667163,  0.06711403],\n",
      "         [ 0.06637754,  0.09681475, -0.04422706, ..., -0.02727465,\n",
      "           0.04594225, -0.03036556]]]], dtype=float32)>, <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
      "array([[[[-0.05395617,  0.06851082, -0.04435276, ...,  0.03964084,\n",
      "          -0.04609153,  0.01077776],\n",
      "         [-0.06291139,  0.05026775, -0.02995185, ..., -0.05942202,\n",
      "           0.06045951,  0.032864  ],\n",
      "         [-0.020976  ,  0.00217127,  0.0577551 , ...,  0.05255158,\n",
      "          -0.00214662,  0.00143252],\n",
      "         ...,\n",
      "         [-0.06909324,  0.05091381,  0.02165922, ..., -0.05219548,\n",
      "          -0.05199059,  0.00023473],\n",
      "         [-0.06950429,  0.05634144,  0.01444973, ...,  0.05314101,\n",
      "          -0.05612062,  0.04890999],\n",
      "         [ 0.01871583, -0.03661884, -0.01186012, ...,  0.0097703 ,\n",
      "          -0.07192156,  0.00188379]],\n",
      "\n",
      "        [[-0.0356085 , -0.00867747,  0.04548002, ...,  0.02360699,\n",
      "          -0.03504239, -0.071069  ],\n",
      "         [ 0.0471705 ,  0.06787255, -0.0036364 , ...,  0.05518228,\n",
      "           0.00339542,  0.04446228],\n",
      "         [-0.04459831, -0.00108798,  0.03739621, ...,  0.0168999 ,\n",
      "           0.00666248,  0.06673062],\n",
      "         ...,\n",
      "         [-0.04649027, -0.02400219, -0.06835891, ...,  0.07016127,\n",
      "           0.07206099,  0.01492006],\n",
      "         [ 0.06485669, -0.04755335, -0.02333822, ..., -0.05898185,\n",
      "          -0.01959215, -0.02898356],\n",
      "         [-0.03695478, -0.00900243,  0.03471753, ..., -0.01603853,\n",
      "           0.04255444,  0.03229522]],\n",
      "\n",
      "        [[ 0.05220823, -0.04168046, -0.06438769, ...,  0.06619187,\n",
      "           0.04832714,  0.01857017],\n",
      "         [ 0.04091778,  0.00632919,  0.05200087, ...,  0.02406131,\n",
      "          -0.00253166,  0.04072148],\n",
      "         [ 0.02334453,  0.06392162,  0.01206405, ...,  0.04691938,\n",
      "          -0.01433627,  0.02743498],\n",
      "         ...,\n",
      "         [ 0.02310298, -0.02449467,  0.04684003, ..., -0.03813725,\n",
      "          -0.06599706,  0.05051775],\n",
      "         [ 0.00779771,  0.00321474, -0.06162126, ...,  0.01059679,\n",
      "           0.05255432,  0.01095346],\n",
      "         [ 0.0127468 ,  0.0390267 , -0.03759265, ..., -0.04632941,\n",
      "          -0.01837325,  0.05581854]]],\n",
      "\n",
      "\n",
      "       [[[ 0.0640863 ,  0.01134308, -0.0425108 , ...,  0.00288264,\n",
      "          -0.02560598, -0.06173389],\n",
      "         [-0.00144809, -0.00698847, -0.0119601 , ...,  0.01507418,\n",
      "          -0.00966295,  0.04988965],\n",
      "         [ 0.03000419,  0.01704571, -0.00493639, ...,  0.01815982,\n",
      "           0.06576838,  0.05378416],\n",
      "         ...,\n",
      "         [-0.02480454,  0.0670684 ,  0.03973569, ..., -0.05748662,\n",
      "           0.04779056, -0.0415703 ],\n",
      "         [ 0.05664815,  0.028111  ,  0.06538898, ...,  0.06762733,\n",
      "           0.0314349 ,  0.00425164],\n",
      "         [ 0.01730852, -0.01691594,  0.05640073, ...,  0.02698098,\n",
      "           0.0634518 ,  0.06194128]],\n",
      "\n",
      "        [[-0.06007516,  0.03542191, -0.02367446, ...,  0.00020494,\n",
      "          -0.04208193, -0.02854922],\n",
      "         [-0.06067781, -0.04377105, -0.07150582, ...,  0.00930966,\n",
      "          -0.0398136 , -0.01218254],\n",
      "         [ 0.05449858, -0.03950653,  0.05083855, ...,  0.01796289,\n",
      "           0.02574883, -0.06577165],\n",
      "         ...,\n",
      "         [ 0.00620966, -0.01522305,  0.01397765, ...,  0.0699124 ,\n",
      "          -0.06477403, -0.02327424],\n",
      "         [ 0.01499265,  0.06211764, -0.0063119 , ..., -0.02255751,\n",
      "          -0.01583143, -0.06611153],\n",
      "         [ 0.04022996, -0.06366489,  0.05329306, ..., -0.0427705 ,\n",
      "           0.02833457,  0.02596952]],\n",
      "\n",
      "        [[-0.01168478, -0.009728  ,  0.0484561 , ...,  0.05236837,\n",
      "          -0.03341505, -0.05715303],\n",
      "         [-0.0493029 , -0.0375434 , -0.0125595 , ..., -0.03569919,\n",
      "           0.03745123,  0.01087562],\n",
      "         [ 0.06028266,  0.01008619, -0.01064707, ...,  0.07003717,\n",
      "           0.02546895, -0.03850251],\n",
      "         ...,\n",
      "         [-0.0414432 ,  0.03718773, -0.05545471, ..., -0.04100402,\n",
      "           0.05434605, -0.00453582],\n",
      "         [-0.0196198 ,  0.0464311 ,  0.05246801, ...,  0.06967346,\n",
      "          -0.03740034, -0.05533389],\n",
      "         [-0.06200559,  0.02903268, -0.04269379, ..., -0.01034628,\n",
      "          -0.00729188, -0.0269997 ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.04348899, -0.03092207,  0.05149962, ...,  0.0721247 ,\n",
      "           0.03549803, -0.0571062 ],\n",
      "         [ 0.00401096, -0.04194001, -0.03075045, ..., -0.04926685,\n",
      "           0.03513888, -0.06835847],\n",
      "         [ 0.02850455,  0.05072299,  0.05004857, ..., -0.07033613,\n",
      "          -0.01445048,  0.01074538],\n",
      "         ...,\n",
      "         [ 0.06554407,  0.01389978, -0.03130668, ..., -0.04014962,\n",
      "           0.02729133,  0.00718278],\n",
      "         [ 0.03859276,  0.05895963, -0.06634458, ..., -0.04200418,\n",
      "          -0.02495035, -0.03762794],\n",
      "         [ 0.06855582,  0.04059711,  0.02691054, ...,  0.07038194,\n",
      "          -0.0218116 , -0.06513557]],\n",
      "\n",
      "        [[-0.03726435, -0.02855035,  0.05602162, ...,  0.04468362,\n",
      "          -0.03167515,  0.05493133],\n",
      "         [-0.05279941,  0.0221406 , -0.0127693 , ..., -0.02430132,\n",
      "           0.0361866 , -0.04717963],\n",
      "         [-0.04284187,  0.00553509, -0.00997447, ..., -0.05961642,\n",
      "           0.04969751,  0.0330758 ],\n",
      "         ...,\n",
      "         [-0.06509261, -0.01561968,  0.05014624, ...,  0.01554658,\n",
      "          -0.06793681, -0.04052625],\n",
      "         [-0.03451701, -0.01879721,  0.04299095, ..., -0.01702055,\n",
      "           0.03472583,  0.02671622],\n",
      "         [ 0.02978855,  0.04673172,  0.06272075, ..., -0.0451028 ,\n",
      "           0.03621535,  0.01477017]],\n",
      "\n",
      "        [[-0.00698861,  0.03067622,  0.03982062, ...,  0.04030859,\n",
      "          -0.07197697, -0.06228786],\n",
      "         [-0.01668669, -0.06979943,  0.06265716, ...,  0.01622137,\n",
      "          -0.04577872,  0.01761171],\n",
      "         [ 0.02676113, -0.0341251 ,  0.00451055, ...,  0.02529465,\n",
      "           0.06686442,  0.01858437],\n",
      "         ...,\n",
      "         [-0.01551508, -0.03896276,  0.02792758, ...,  0.06010245,\n",
      "          -0.05518204,  0.05450536],\n",
      "         [-0.05155642,  0.0298866 ,  0.05874895, ..., -0.00829447,\n",
      "           0.05142472, -0.07112174],\n",
      "         [ 0.01460228,  0.03731676,  0.0018172 , ..., -0.01335878,\n",
      "          -0.06292125, -0.02317921]]]], dtype=float32)>, <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32, numpy=\n",
      "array([[[[-0.00709487,  0.03810718,  0.00376213, ...,  0.01587863,\n",
      "          -0.04961922,  0.01034334],\n",
      "         [-0.000732  , -0.00842756,  0.05271586, ...,  0.04836849,\n",
      "           0.02622273, -0.01339812],\n",
      "         [ 0.03969527,  0.0045696 ,  0.00485869, ..., -0.03385419,\n",
      "           0.03121199, -0.04183552],\n",
      "         ...,\n",
      "         [ 0.02460283, -0.04113483, -0.0119529 , ..., -0.05293712,\n",
      "          -0.02166359,  0.04124828],\n",
      "         [-0.0388258 , -0.03716155, -0.0306877 , ..., -0.0260116 ,\n",
      "           0.01146178, -0.05643309],\n",
      "         [-0.00173002, -0.0544638 ,  0.0141528 , ..., -0.021504  ,\n",
      "          -0.02783159, -0.00163477]],\n",
      "\n",
      "        [[ 0.01214508,  0.03637308, -0.03155836, ...,  0.00913387,\n",
      "          -0.03411025,  0.0485064 ],\n",
      "         [ 0.04781954,  0.03704591,  0.0194292 , ...,  0.02697838,\n",
      "          -0.05168434,  0.03095919],\n",
      "         [-0.05351224, -0.03133075,  0.024089  , ..., -0.04531883,\n",
      "           0.04616333, -0.02888569],\n",
      "         ...,\n",
      "         [ 0.05170903, -0.02270482, -0.03308962, ..., -0.05379778,\n",
      "          -0.01572357,  0.00215535],\n",
      "         [ 0.04807315, -0.00371555,  0.01097718, ...,  0.05549488,\n",
      "          -0.02191757,  0.03916023],\n",
      "         [ 0.01287336,  0.05264178, -0.05366518, ...,  0.03702339,\n",
      "           0.00599306,  0.0561204 ]],\n",
      "\n",
      "        [[-0.05562037,  0.00104365,  0.00448173, ...,  0.04439418,\n",
      "           0.03395607, -0.00252819],\n",
      "         [ 0.01422429, -0.03936072,  0.05166033, ..., -0.04757431,\n",
      "          -0.00260041,  0.03567022],\n",
      "         [ 0.02384747, -0.0470157 , -0.03188612, ...,  0.04695645,\n",
      "           0.02455333, -0.03220851],\n",
      "         ...,\n",
      "         [ 0.00099479,  0.03223136,  0.04364187, ..., -0.02641353,\n",
      "          -0.03101713, -0.01410114],\n",
      "         [-0.00618911,  0.02801269,  0.00392713, ...,  0.0325377 ,\n",
      "          -0.0398966 ,  0.03933769],\n",
      "         [ 0.01530867,  0.03302888, -0.0066126 , ...,  0.04297838,\n",
      "          -0.01730918,  0.01372531]]],\n",
      "\n",
      "\n",
      "       [[[ 0.02752719,  0.03713189,  0.0066506 , ..., -0.03887034,\n",
      "           0.00020513, -0.01622901],\n",
      "         [ 0.04118935, -0.02874783,  0.02193079, ...,  0.05671339,\n",
      "          -0.02663361,  0.03497894],\n",
      "         [-0.04371308, -0.0494568 ,  0.01911826, ..., -0.05508588,\n",
      "          -0.0427785 , -0.01294607],\n",
      "         ...,\n",
      "         [ 0.04152038,  0.04940886,  0.0171021 , ..., -0.02568477,\n",
      "           0.02893521,  0.02272649],\n",
      "         [-0.02922475,  0.00339462,  0.01051463, ...,  0.03537878,\n",
      "          -0.05237069, -0.00834472],\n",
      "         [ 0.0404158 ,  0.03275351,  0.04423064, ...,  0.00880696,\n",
      "          -0.03653497,  0.05688224]],\n",
      "\n",
      "        [[-0.00899032,  0.02456642, -0.02206604, ..., -0.03021449,\n",
      "           0.04563197, -0.04920577],\n",
      "         [ 0.05605948, -0.02020052, -0.01969333, ...,  0.01075758,\n",
      "          -0.05380379,  0.00817025],\n",
      "         [ 0.01841648,  0.01048254, -0.04182305, ...,  0.01477142,\n",
      "          -0.01601616,  0.04591934],\n",
      "         ...,\n",
      "         [ 0.01668159, -0.02008101,  0.00974284, ..., -0.05328073,\n",
      "           0.05486341, -0.03530116],\n",
      "         [-0.04216583,  0.04759127, -0.02856824, ...,  0.04179851,\n",
      "          -0.01258025, -0.03185188],\n",
      "         [ 0.00905097,  0.04835022, -0.0552872 , ...,  0.04699343,\n",
      "           0.0420051 , -0.04022197]],\n",
      "\n",
      "        [[-0.03188283,  0.01432956, -0.03069986, ...,  0.00961965,\n",
      "          -0.04754904,  0.02551268],\n",
      "         [-0.04937404, -0.04009545,  0.02386449, ..., -0.00282142,\n",
      "           0.03277124, -0.00184854],\n",
      "         [ 0.05631162,  0.02141292,  0.02689815, ..., -0.05133738,\n",
      "          -0.03018861,  0.01624647],\n",
      "         ...,\n",
      "         [ 0.00909228,  0.04652803, -0.02972832, ..., -0.04465588,\n",
      "           0.00863988,  0.01173752],\n",
      "         [ 0.01090349, -0.04853725, -0.03147121, ..., -0.00579823,\n",
      "           0.02919036,  0.01227478],\n",
      "         [ 0.03403418, -0.02811514,  0.00922171, ..., -0.05074919,\n",
      "           0.04154665, -0.01325781]]],\n",
      "\n",
      "\n",
      "       [[[ 0.02293702,  0.05243753, -0.00060372, ...,  0.01702647,\n",
      "          -0.00036423,  0.03527167],\n",
      "         [-0.00404809,  0.05261864, -0.00748271, ..., -0.01779225,\n",
      "           0.05015096, -0.01795214],\n",
      "         [ 0.03371194, -0.01011176,  0.01782138, ...,  0.05557902,\n",
      "           0.00264203,  0.0072769 ],\n",
      "         ...,\n",
      "         [-0.04039895,  0.05232881, -0.00048896, ..., -0.00258808,\n",
      "          -0.04373373, -0.01682829],\n",
      "         [ 0.02581685, -0.0355304 , -0.01244037, ...,  0.04907333,\n",
      "          -0.0005848 , -0.00392089],\n",
      "         [ 0.03899741,  0.0389446 ,  0.05483066, ...,  0.00422452,\n",
      "           0.0038595 ,  0.01825077]],\n",
      "\n",
      "        [[-0.04104024,  0.02890309, -0.01581773, ..., -0.01594962,\n",
      "           0.0518841 ,  0.03287643],\n",
      "         [-0.00792802,  0.03985749,  0.02215587, ...,  0.03015522,\n",
      "           0.03192988,  0.03368146],\n",
      "         [ 0.0245101 , -0.04326718, -0.04445966, ..., -0.02146147,\n",
      "          -0.04480352, -0.02249039],\n",
      "         ...,\n",
      "         [ 0.0312275 , -0.0253532 , -0.0060786 , ...,  0.05461109,\n",
      "           0.03274272, -0.02548553],\n",
      "         [ 0.03491986,  0.04786981,  0.04188607, ...,  0.02554429,\n",
      "          -0.04572964, -0.04366235],\n",
      "         [-0.03736489,  0.0205448 , -0.03266603, ...,  0.013292  ,\n",
      "          -0.01977355,  0.02865062]],\n",
      "\n",
      "        [[-0.00538019,  0.02884666, -0.03017754, ..., -0.04527771,\n",
      "          -0.00192884,  0.00098035],\n",
      "         [ 0.00824676,  0.04112847,  0.0452616 , ..., -0.00664399,\n",
      "           0.04497882, -0.01255145],\n",
      "         [ 0.0479767 ,  0.00933629,  0.04747525, ..., -0.01833672,\n",
      "           0.03412334, -0.0268672 ],\n",
      "         ...,\n",
      "         [-0.01053344, -0.00403059, -0.01736476, ...,  0.036749  ,\n",
      "          -0.05788998, -0.02138867],\n",
      "         [-0.00333552,  0.00981013, -0.05022395, ...,  0.04675495,\n",
      "           0.01152677,  0.01009948],\n",
      "         [ 0.01694754, -0.04595543, -0.05589278, ..., -0.01099406,\n",
      "          -0.03193308,  0.01851396]]]], dtype=float32)>, <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32, numpy=\n",
      "array([[[[-0.04402533, -0.044297  ,  0.01230965, ...,  0.01052892,\n",
      "          -0.04618401,  0.01196254],\n",
      "         [-0.0198517 , -0.04418318, -0.0249224 , ..., -0.04368895,\n",
      "           0.03095642,  0.04558529],\n",
      "         [ 0.03780691,  0.05046462, -0.03266833, ...,  0.03178345,\n",
      "          -0.02378845,  0.02836151],\n",
      "         ...,\n",
      "         [-0.03894963, -0.03946716,  0.05101793, ..., -0.00202243,\n",
      "          -0.04298538,  0.04432038],\n",
      "         [ 0.00378189,  0.03987626, -0.0281658 , ..., -0.01182849,\n",
      "          -0.03418406, -0.01958074],\n",
      "         [-0.01949985, -0.00676353,  0.04554334, ...,  0.01326729,\n",
      "           0.0378243 , -0.01570282]],\n",
      "\n",
      "        [[-0.04969326,  0.03511809,  0.04464929, ...,  0.00778837,\n",
      "           0.01851833,  0.02402309],\n",
      "         [ 0.03705837, -0.02967959,  0.05013442, ..., -0.05016405,\n",
      "           0.02600875, -0.02465634],\n",
      "         [ 0.02212913,  0.01580197,  0.010222  , ..., -0.00153104,\n",
      "           0.00092592,  0.00524712],\n",
      "         ...,\n",
      "         [-0.01243836, -0.00610299, -0.01374144, ..., -0.00773519,\n",
      "          -0.01632083, -0.03670916],\n",
      "         [ 0.04960479,  0.04414769,  0.00792804, ..., -0.00630388,\n",
      "           0.02859502, -0.01061434],\n",
      "         [-0.02248164,  0.01422608,  0.0291633 , ...,  0.03419498,\n",
      "          -0.01029113,  0.03089317]],\n",
      "\n",
      "        [[ 0.03256071, -0.02029847, -0.0039206 , ...,  0.03506291,\n",
      "          -0.01635251,  0.03584933],\n",
      "         [-0.03900884, -0.03678807,  0.007376  , ..., -0.01930522,\n",
      "           0.01359043, -0.01340351],\n",
      "         [-0.00594481, -0.01662288, -0.04704723, ..., -0.02685554,\n",
      "          -0.03990528, -0.04977278],\n",
      "         ...,\n",
      "         [ 0.01309508,  0.0437287 , -0.04457989, ...,  0.02821234,\n",
      "          -0.00801231, -0.02079964],\n",
      "         [-0.02833629,  0.04070809, -0.00295793, ..., -0.03860322,\n",
      "           0.0168146 , -0.00858573],\n",
      "         [ 0.01114592, -0.04691386, -0.00627956, ...,  0.04729479,\n",
      "           0.04468127,  0.02766573]]],\n",
      "\n",
      "\n",
      "       [[[-0.03799037, -0.0363499 , -0.03813128, ..., -0.05068922,\n",
      "          -0.03890089,  0.03657439],\n",
      "         [-0.02004462,  0.00613964,  0.02327595, ..., -0.04200958,\n",
      "          -0.03937045, -0.02830376],\n",
      "         [-0.04889368,  0.02769178, -0.00346974, ..., -0.04996253,\n",
      "          -0.02101678,  0.02599254],\n",
      "         ...,\n",
      "         [-0.0252587 , -0.03769117,  0.01827484, ...,  0.02141719,\n",
      "           0.020486  , -0.0006837 ],\n",
      "         [ 0.0230991 ,  0.04330701,  0.03178204, ...,  0.03623927,\n",
      "          -0.0307162 , -0.04401233],\n",
      "         [ 0.00818883,  0.00649539,  0.04673601, ..., -0.02506887,\n",
      "           0.01482328,  0.0248016 ]],\n",
      "\n",
      "        [[-0.0066088 , -0.00330959,  0.04938178, ...,  0.03947353,\n",
      "           0.00313255,  0.01227711],\n",
      "         [-0.03695651, -0.03144352, -0.01593312, ...,  0.03260829,\n",
      "          -0.02701715, -0.00755991],\n",
      "         [-0.03510786, -0.02785179, -0.0466549 , ...,  0.03036211,\n",
      "          -0.0425081 , -0.02734657],\n",
      "         ...,\n",
      "         [ 0.02792516, -0.00191867,  0.02525857, ..., -0.00571347,\n",
      "          -0.05016778,  0.02478348],\n",
      "         [-0.02614973,  0.03362535,  0.01446121, ...,  0.03905451,\n",
      "          -0.02033179,  0.03433517],\n",
      "         [ 0.02455147, -0.01613005, -0.02383645, ..., -0.02212511,\n",
      "           0.05060077, -0.00124298]],\n",
      "\n",
      "        [[-0.01947556,  0.00259288,  0.02580535, ...,  0.04389783,\n",
      "           0.02950589, -0.01293584],\n",
      "         [ 0.0412975 ,  0.01979309, -0.02699715, ..., -0.02320082,\n",
      "           0.02479138, -0.01256326],\n",
      "         [ 0.04109452, -0.01338721,  0.01091973, ...,  0.03168666,\n",
      "          -0.03393586, -0.03565478],\n",
      "         ...,\n",
      "         [-0.00811649, -0.02568108, -0.01695636, ...,  0.03792005,\n",
      "          -0.0022176 ,  0.03378258],\n",
      "         [-0.01369725, -0.04204781, -0.00696634, ...,  0.00950156,\n",
      "          -0.04913736, -0.03221583],\n",
      "         [ 0.02091953, -0.03542263,  0.02145314, ..., -0.00710319,\n",
      "          -0.0207724 ,  0.02512856]]],\n",
      "\n",
      "\n",
      "       [[[-0.03011264, -0.01362837, -0.03880656, ...,  0.01258112,\n",
      "           0.01956505,  0.04640168],\n",
      "         [ 0.04851788,  0.04784706,  0.00931524, ..., -0.01065796,\n",
      "          -0.00677179,  0.02335425],\n",
      "         [-0.03750653, -0.03957809,  0.0228449 , ..., -0.01591758,\n",
      "           0.02198181,  0.0280419 ],\n",
      "         ...,\n",
      "         [-0.02128094,  0.01248178,  0.04768211, ..., -0.02587641,\n",
      "           0.01896292,  0.03765593],\n",
      "         [ 0.00442282,  0.03258327,  0.01779151, ...,  0.0120657 ,\n",
      "          -0.00682274, -0.00734183],\n",
      "         [-0.03948782, -0.03028492, -0.02091791, ..., -0.01609468,\n",
      "           0.01710153,  0.02063838]],\n",
      "\n",
      "        [[ 0.01057503, -0.01518556,  0.02209982, ...,  0.00223286,\n",
      "          -0.02444769,  0.01923754],\n",
      "         [ 0.04173218, -0.04028846, -0.0028483 , ..., -0.01916968,\n",
      "          -0.00698421, -0.01216863],\n",
      "         [ 0.02900557,  0.02940193, -0.03350301, ..., -0.03184208,\n",
      "          -0.00715458, -0.04070048],\n",
      "         ...,\n",
      "         [ 0.0034482 , -0.00598929,  0.04377266, ..., -0.04905559,\n",
      "          -0.04954565,  0.01902627],\n",
      "         [-0.0074678 ,  0.00977482, -0.00988531, ..., -0.01316632,\n",
      "           0.03857417,  0.02451401],\n",
      "         [-0.05045674,  0.03853627,  0.03149297, ..., -0.01681238,\n",
      "           0.02992158,  0.03282201]],\n",
      "\n",
      "        [[-0.03985023,  0.00587821,  0.04887873, ...,  0.03666655,\n",
      "          -0.02837131, -0.04678705],\n",
      "         [ 0.02816863,  0.01883329, -0.034919  , ..., -0.01647839,\n",
      "          -0.00457262, -0.02313087],\n",
      "         [ 0.01647557,  0.03024528,  0.02224837, ..., -0.02346176,\n",
      "           0.01906961,  0.04664253],\n",
      "         ...,\n",
      "         [ 0.03770762,  0.01237391, -0.01396369, ..., -0.01285838,\n",
      "          -0.00903539,  0.01229985],\n",
      "         [-0.03325401, -0.01797767, -0.03528039, ...,  0.00158693,\n",
      "           0.01533863,  0.03344161],\n",
      "         [ 0.02776904,  0.03583713, -0.0386654 , ...,  0.00079703,\n",
      "           0.01815566, -0.01557733]]]], dtype=float32)>, <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32, numpy=\n",
      "array([[[[ 0.01590561,  0.03215453, -0.03624433, ...,  0.01200674,\n",
      "           0.02843149, -0.01972401],\n",
      "         [ 0.02492519,  0.01050781,  0.00053986, ...,  0.04020862,\n",
      "          -0.01637388, -0.0002932 ],\n",
      "         [-0.03018175, -0.02827597, -0.01544299, ..., -0.01759717,\n",
      "           0.01965393, -0.01177303],\n",
      "         ...,\n",
      "         [-0.01078684,  0.01874085,  0.02273418, ..., -0.00978249,\n",
      "           0.02499238, -0.01063826],\n",
      "         [-0.03129344, -0.01119944,  0.02660871, ..., -0.01850302,\n",
      "           0.01880104, -0.03039033],\n",
      "         [-0.03407736, -0.0041963 ,  0.02305626, ...,  0.03932372,\n",
      "           0.00342001, -0.01450177]],\n",
      "\n",
      "        [[-0.03009268, -0.03005857, -0.03992533, ...,  0.01118444,\n",
      "           0.02179331,  0.03246662],\n",
      "         [-0.03014193, -0.02194193, -0.03475143, ...,  0.03581973,\n",
      "          -0.02695193,  0.02332782],\n",
      "         [-0.02219431, -0.00738849, -0.02155268, ...,  0.00199271,\n",
      "           0.04018088, -0.03054346],\n",
      "         ...,\n",
      "         [-0.02350307, -0.02992245, -0.01296968, ...,  0.02452783,\n",
      "          -0.00048269,  0.0385772 ],\n",
      "         [-0.03939552,  0.03843557,  0.0403573 , ...,  0.03855548,\n",
      "           0.00277629,  0.01400723],\n",
      "         [ 0.03348226, -0.03173904, -0.03138754, ..., -0.02382153,\n",
      "          -0.01877579,  0.01571136]],\n",
      "\n",
      "        [[ 0.02227262, -0.0193799 , -0.00653458, ...,  0.02106947,\n",
      "           0.0027178 ,  0.02843867],\n",
      "         [ 0.00979884,  0.03988303, -0.01174443, ..., -0.02300008,\n",
      "          -0.03562971,  0.03855333],\n",
      "         [-0.00999688, -0.00699244, -0.01319253, ..., -0.02119968,\n",
      "           0.01703201, -0.02334481],\n",
      "         ...,\n",
      "         [ 0.01401616,  0.0169189 , -0.01535632, ..., -0.02927658,\n",
      "          -0.02869807, -0.01251455],\n",
      "         [ 0.02551852,  0.01165221,  0.0173655 , ..., -0.01655027,\n",
      "          -0.02372853, -0.01863547],\n",
      "         [-0.01919465,  0.01473778, -0.01276567, ..., -0.03420925,\n",
      "          -0.0191354 , -0.02074856]]],\n",
      "\n",
      "\n",
      "       [[[-0.02179249,  0.02388682, -0.03447556, ...,  0.0288703 ,\n",
      "          -0.03280821,  0.004256  ],\n",
      "         [ 0.03182921,  0.0192642 , -0.0123819 , ..., -0.03952062,\n",
      "          -0.01407179,  0.00337784],\n",
      "         [-0.01168565, -0.03449536, -0.01816406, ..., -0.03713868,\n",
      "          -0.00918059,  0.03210679],\n",
      "         ...,\n",
      "         [-0.01052254, -0.01659763,  0.01897401, ..., -0.0381881 ,\n",
      "           0.00410406,  0.03783568],\n",
      "         [-0.00286202,  0.02510016,  0.02570692, ...,  0.02614823,\n",
      "          -0.01261581, -0.00050407],\n",
      "         [-0.02400553, -0.03456005, -0.00857745, ...,  0.03745643,\n",
      "           0.01609994,  0.01611865]],\n",
      "\n",
      "        [[-0.0234554 ,  0.0002269 ,  0.0113355 , ..., -0.03313823,\n",
      "          -0.027903  , -0.03277236],\n",
      "         [-0.0096637 , -0.00591685,  0.00742314, ...,  0.02506508,\n",
      "          -0.02523583,  0.0242102 ],\n",
      "         [-0.03398683,  0.0045422 ,  0.02949344, ...,  0.00897318,\n",
      "          -0.02765234,  0.0199168 ],\n",
      "         ...,\n",
      "         [-0.01485166,  0.03718798,  0.02381732, ...,  0.03508117,\n",
      "           0.03033619,  0.01116696],\n",
      "         [-0.0261065 ,  0.00464783, -0.03977669, ...,  0.0273835 ,\n",
      "           0.01237097, -0.03171295],\n",
      "         [-0.01141696,  0.0268104 , -0.0238735 , ...,  0.01967459,\n",
      "          -0.0365955 ,  0.02625287]],\n",
      "\n",
      "        [[-0.02903796, -0.00934748, -0.00342854, ...,  0.01433143,\n",
      "          -0.04077073,  0.03234864],\n",
      "         [ 0.00530105,  0.00204771,  0.03259808, ...,  0.03408046,\n",
      "           0.00574942,  0.01208879],\n",
      "         [ 0.02823506,  0.02445425,  0.02817635, ...,  0.02069006,\n",
      "           0.01860997,  0.00717862],\n",
      "         ...,\n",
      "         [-0.01057937,  0.03214558,  0.03569463, ...,  0.00020958,\n",
      "          -0.03374658,  0.04036123],\n",
      "         [ 0.01966031, -0.02332435,  0.01790488, ..., -0.04009221,\n",
      "          -0.03047415,  0.02637564],\n",
      "         [ 0.02340527, -0.00167291,  0.02088793, ...,  0.01581557,\n",
      "           0.02531781,  0.01182792]]],\n",
      "\n",
      "\n",
      "       [[[-0.02400311, -0.01985408, -0.00330054, ..., -0.0374771 ,\n",
      "           0.01007792,  0.02001352],\n",
      "         [-0.04162387, -0.02608358,  0.03992319, ..., -0.0340628 ,\n",
      "           0.00452158, -0.01564184],\n",
      "         [ 0.01635467,  0.01497634, -0.01189245, ..., -0.02057785,\n",
      "          -0.00292533, -0.02692726],\n",
      "         ...,\n",
      "         [-0.01916962,  0.03905753,  0.02924149, ..., -0.0237261 ,\n",
      "           0.0075636 , -0.03198162],\n",
      "         [-0.00105922,  0.01264925, -0.00797025, ...,  0.03591045,\n",
      "           0.01427937,  0.01576455],\n",
      "         [-0.0124269 , -0.01326258, -0.03989028, ..., -0.03433321,\n",
      "          -0.01557233,  0.025908  ]],\n",
      "\n",
      "        [[ 0.04054547,  0.03179274,  0.0183113 , ..., -0.00109102,\n",
      "          -0.03771813,  0.03788343],\n",
      "         [ 0.03568117,  0.03423469, -0.01777199, ...,  0.00672306,\n",
      "          -0.03589993, -0.02713366],\n",
      "         [ 0.02498596,  0.03418474, -0.00754078, ..., -0.03698112,\n",
      "           0.00359455,  0.01333214],\n",
      "         ...,\n",
      "         [ 0.02329827, -0.01646419, -0.00163931, ..., -0.02404568,\n",
      "           0.02100924,  0.04142324],\n",
      "         [-0.01273826,  0.00085002,  0.02408688, ..., -0.0345968 ,\n",
      "          -0.01846613,  0.01855664],\n",
      "         [ 0.02871517, -0.01397358,  0.00811689, ...,  0.03421535,\n",
      "          -0.03645797,  0.03686313]],\n",
      "\n",
      "        [[-0.02487206, -0.02557854,  0.03502582, ...,  0.00456553,\n",
      "           0.03686423,  0.02285672],\n",
      "         [-0.03734821,  0.03815537, -0.03763605, ..., -0.00013748,\n",
      "          -0.03907797,  0.00061865],\n",
      "         [ 0.03776933, -0.02199747, -0.00060326, ...,  0.02372257,\n",
      "           0.03885094,  0.03544088],\n",
      "         ...,\n",
      "         [-0.03200239,  0.01255802,  0.03380032, ...,  0.02011295,\n",
      "          -0.01718071, -0.0135065 ],\n",
      "         [-0.02536611, -0.03651285,  0.02785836, ..., -0.00483451,\n",
      "          -0.00316067,  0.02295618],\n",
      "         [-0.03866577, -0.03182986, -0.02500706, ..., -0.0326561 ,\n",
      "           0.0057113 ,  0.035985  ]]]], dtype=float32)>, <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32, numpy=\n",
      "array([[[[ 3.41661498e-02,  6.93037733e-03,  3.46210971e-02, ...,\n",
      "          -3.97555903e-03, -1.39493737e-02, -2.21518017e-02],\n",
      "         [ 1.77686587e-02,  2.68880650e-02,  2.72937566e-02, ...,\n",
      "           8.87317583e-03, -4.79294732e-03,  3.98736447e-03],\n",
      "         [-9.28494893e-03,  1.34105496e-02,  2.04606391e-02, ...,\n",
      "           2.69758180e-02, -1.93410013e-02, -2.40811445e-02],\n",
      "         ...,\n",
      "         [-2.51820683e-02, -1.64171215e-02, -3.56205516e-02, ...,\n",
      "          -2.57193297e-03,  1.16578639e-02,  6.64133579e-04],\n",
      "         [ 1.00143775e-02,  2.82578692e-02,  9.27740335e-03, ...,\n",
      "          -1.18475724e-02,  3.33617106e-02, -2.20285952e-02],\n",
      "         [-3.36755253e-02,  1.35354139e-02, -1.24807246e-02, ...,\n",
      "          -1.93255339e-02, -1.14473440e-02,  2.68911123e-02]],\n",
      "\n",
      "        [[ 3.36842164e-02, -8.34297761e-03, -1.84615832e-02, ...,\n",
      "           2.08890699e-02, -3.32144275e-03, -2.78067552e-02],\n",
      "         [-2.43931562e-02, -2.82803513e-02, -4.14527953e-04, ...,\n",
      "           2.52050720e-02,  9.48246941e-03,  1.23994499e-02],\n",
      "         [-2.31474563e-02,  3.48623618e-02,  2.83467174e-02, ...,\n",
      "          -3.00271809e-03, -8.29271786e-03,  2.72043720e-02],\n",
      "         ...,\n",
      "         [-2.70979814e-02, -5.46169095e-03,  3.51586863e-02, ...,\n",
      "          -6.92162663e-03,  1.38434879e-02,  1.34275816e-02],\n",
      "         [-2.94846948e-02, -3.41587402e-02,  1.68880448e-03, ...,\n",
      "          -1.81195550e-02,  3.17178220e-02, -4.88965772e-03],\n",
      "         [ 3.44212130e-02,  1.26587152e-02,  1.67477839e-02, ...,\n",
      "           9.05359909e-03, -1.15130972e-02, -2.78460793e-02]],\n",
      "\n",
      "        [[ 5.64568862e-03, -1.46866590e-02, -2.98424158e-02, ...,\n",
      "           5.54848835e-03,  2.95255631e-02, -1.08619742e-02],\n",
      "         [-1.75288338e-02, -2.50375085e-02, -1.12481285e-02, ...,\n",
      "          -2.31798403e-02,  2.76602283e-02,  2.74966881e-02],\n",
      "         [-2.89589539e-02, -2.56895274e-02,  3.09333280e-02, ...,\n",
      "           1.36412680e-04,  5.08516282e-03, -1.71263609e-02],\n",
      "         ...,\n",
      "         [ 2.34346464e-03, -2.51196958e-02, -3.28641906e-02, ...,\n",
      "          -5.12434356e-03,  3.37372124e-02,  3.05272713e-02],\n",
      "         [ 2.93774456e-02,  1.92242041e-02,  3.24203372e-02, ...,\n",
      "          -7.91870244e-03, -2.56336071e-02,  2.53837369e-02],\n",
      "         [-4.77231666e-03, -1.13080405e-02,  2.99366042e-02, ...,\n",
      "           2.88920850e-02, -8.98967870e-03, -1.91462860e-02]]],\n",
      "\n",
      "\n",
      "       [[[-1.48062520e-02,  1.70844793e-03,  3.37009951e-02, ...,\n",
      "           8.49927217e-03,  3.32851857e-02,  1.20528601e-02],\n",
      "         [-2.89212894e-02, -9.80463251e-03,  1.24429539e-03, ...,\n",
      "           3.25880274e-02,  2.50386968e-02, -2.71210466e-02],\n",
      "         [-5.87544404e-03,  1.78371891e-02,  1.83955468e-02, ...,\n",
      "          -2.22122036e-02, -3.59436013e-02, -1.49624683e-02],\n",
      "         ...,\n",
      "         [-3.30427587e-02, -1.99980792e-02,  1.90325156e-02, ...,\n",
      "           5.97395003e-03, -1.31141171e-02, -1.73320025e-02],\n",
      "         [-2.39444748e-02,  1.72650442e-02, -2.53661349e-02, ...,\n",
      "          -6.80996664e-03, -3.15339565e-02, -5.11503406e-03],\n",
      "         [-3.54902036e-02, -3.45476046e-02, -3.57432850e-02, ...,\n",
      "          -1.11113377e-02,  8.45174864e-03, -6.32808357e-03]],\n",
      "\n",
      "        [[-2.72268653e-02,  5.57921827e-03, -2.97541823e-02, ...,\n",
      "           4.66680899e-03,  2.67694220e-02,  1.73631720e-02],\n",
      "         [-2.41179913e-02, -3.13570090e-02,  2.34011821e-02, ...,\n",
      "          -2.80706584e-03,  9.12171975e-03, -1.34194270e-03],\n",
      "         [-1.60876550e-02,  1.13489814e-02,  2.54425146e-02, ...,\n",
      "          -1.98013764e-02, -5.30567020e-04, -1.56957656e-04],\n",
      "         ...,\n",
      "         [-2.26758122e-02,  2.79211551e-02,  1.23715922e-02, ...,\n",
      "           1.75977722e-02,  1.19722411e-02, -2.55472586e-03],\n",
      "         [ 8.48285481e-03,  2.60624588e-02,  1.66423209e-02, ...,\n",
      "           8.13989714e-03, -1.88017450e-02,  9.44031402e-03],\n",
      "         [ 1.73752420e-02, -1.36838723e-02, -1.39407068e-03, ...,\n",
      "          -3.49980742e-02, -2.30819434e-02, -2.54645273e-02]],\n",
      "\n",
      "        [[-1.96212847e-02, -3.43119726e-02, -2.00702939e-02, ...,\n",
      "           3.60416174e-02,  5.58168069e-03, -3.16580683e-02],\n",
      "         [-8.12398270e-03,  6.17133453e-03,  3.49882618e-02, ...,\n",
      "           1.06546357e-02,  3.36506814e-02,  9.50134546e-03],\n",
      "         [ 1.99108496e-02,  1.94478035e-02, -3.25420722e-02, ...,\n",
      "          -8.88438523e-03, -4.29249927e-03,  3.03329304e-02],\n",
      "         ...,\n",
      "         [ 1.82914287e-02, -1.55786388e-02, -7.82434270e-03, ...,\n",
      "           2.13375017e-02, -5.23670949e-03,  2.43270770e-03],\n",
      "         [-1.04054362e-02, -1.07726213e-02, -2.58240886e-02, ...,\n",
      "          -1.04531497e-02,  2.53577642e-02,  3.30812261e-02],\n",
      "         [ 1.97191723e-02, -1.38106402e-02,  3.93930450e-03, ...,\n",
      "          -6.48992695e-03, -2.37323102e-02, -3.39312442e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 3.19259241e-02,  3.32009792e-02, -2.99227703e-02, ...,\n",
      "           3.40487808e-02, -1.04347821e-02,  1.71686634e-02],\n",
      "         [ 1.02486871e-02,  1.30506419e-02, -1.07660890e-06, ...,\n",
      "          -1.54163297e-02,  6.70178235e-03, -2.23140661e-02],\n",
      "         [ 3.50081697e-02,  1.49024948e-02,  2.88306028e-02, ...,\n",
      "          -1.47285648e-02,  3.44104767e-02, -5.92270307e-03],\n",
      "         ...,\n",
      "         [-1.03271753e-03, -2.21365131e-02,  1.25452876e-04, ...,\n",
      "          -3.22187692e-03,  7.95062631e-04, -8.20937753e-03],\n",
      "         [-2.74967141e-02,  4.95234132e-03, -3.92902642e-03, ...,\n",
      "          -2.92390399e-02,  3.06225717e-02, -1.34447031e-02],\n",
      "         [ 2.72538885e-03,  3.53721902e-03, -1.90353226e-02, ...,\n",
      "          -3.58855873e-02,  4.17458639e-03, -2.60941014e-02]],\n",
      "\n",
      "        [[-3.67128104e-03, -1.64148677e-02, -3.63473594e-03, ...,\n",
      "          -2.92606764e-02, -3.48083153e-02, -1.04547068e-02],\n",
      "         [ 9.56555083e-03, -2.09261570e-02,  2.41925716e-02, ...,\n",
      "          -2.90348176e-02,  2.06561722e-02,  1.91375278e-02],\n",
      "         [-2.18929909e-02,  2.52835006e-02,  5.82709536e-03, ...,\n",
      "          -1.17047336e-02,  6.13023713e-03, -3.26020941e-02],\n",
      "         ...,\n",
      "         [ 5.27819246e-03, -2.29766928e-02,  2.85718963e-03, ...,\n",
      "          -3.83719429e-03,  3.57866660e-02, -1.78559627e-02],\n",
      "         [ 1.46879070e-02,  3.00312042e-02, -2.65254639e-02, ...,\n",
      "           2.47334540e-02, -9.28696245e-03,  1.77418329e-02],\n",
      "         [ 1.57753378e-03,  3.29172164e-02, -7.85070285e-03, ...,\n",
      "           1.50694996e-02,  1.23641007e-02, -1.48273651e-02]],\n",
      "\n",
      "        [[-4.01938334e-03,  1.45779848e-02, -1.37919113e-02, ...,\n",
      "          -2.82249488e-02,  2.07445174e-02, -2.97982618e-03],\n",
      "         [-7.63108954e-03, -1.77552793e-02, -2.92526074e-02, ...,\n",
      "          -3.32051143e-03,  1.63960457e-02,  3.36091518e-02],\n",
      "         [ 5.96158206e-04, -2.42581107e-02, -2.00902615e-02, ...,\n",
      "          -1.47105251e-02, -2.66408678e-02,  3.47960070e-02],\n",
      "         ...,\n",
      "         [ 1.49750970e-02, -3.08749024e-02, -2.54487619e-03, ...,\n",
      "          -9.14705731e-03, -7.63771310e-03,  2.56517008e-02],\n",
      "         [-2.58301981e-02,  4.42163646e-03,  2.18320452e-02, ...,\n",
      "           3.46361920e-02,  2.92540342e-02, -1.41149350e-02],\n",
      "         [ 2.06265002e-02,  7.52393156e-04, -7.03703798e-03, ...,\n",
      "          -3.97132710e-03, -3.09040658e-02,  1.32248402e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32, numpy=\n",
      "array([[[[ 0.02612906,  0.01334459,  0.00084784, ...,  0.00033463,\n",
      "          -0.0076605 , -0.02979894],\n",
      "         [ 0.01339933,  0.02949721,  0.00298193, ...,  0.00582734,\n",
      "           0.02461761,  0.03089093],\n",
      "         [-0.00595657,  0.02358972,  0.01640318, ..., -0.02605328,\n",
      "          -0.01059385, -0.00576568],\n",
      "         ...,\n",
      "         [ 0.03439299,  0.03004898, -0.02538895, ...,  0.02336685,\n",
      "           0.0208191 ,  0.00208189],\n",
      "         [-0.03059338,  0.01797189, -0.00365789, ...,  0.02053444,\n",
      "          -0.02422528,  0.01060333],\n",
      "         [ 0.03274629, -0.01039246, -0.03407728, ..., -0.03085329,\n",
      "          -0.01603336, -0.02898944]],\n",
      "\n",
      "        [[ 0.02544508,  0.03174481,  0.03035536, ..., -0.00230153,\n",
      "          -0.00112263, -0.02855675],\n",
      "         [ 0.00790936,  0.01254462, -0.0038447 , ...,  0.01564755,\n",
      "          -0.01046371, -0.03004333],\n",
      "         [ 0.00965694, -0.02153179, -0.01883473, ..., -0.01729744,\n",
      "          -0.01083923, -0.0324553 ],\n",
      "         ...,\n",
      "         [ 0.01839969, -0.02712397, -0.03340108, ..., -0.03422118,\n",
      "          -0.02257374,  0.03389611],\n",
      "         [-0.00031559, -0.01211032, -0.02213022, ...,  0.0064643 ,\n",
      "           0.02178949,  0.02447857],\n",
      "         [-0.00650836,  0.00038861,  0.02712695, ...,  0.03302369,\n",
      "           0.01590218,  0.00435861]],\n",
      "\n",
      "        [[ 0.00160223,  0.01398719, -0.03538166, ..., -0.01141886,\n",
      "           0.01486073, -0.00087697],\n",
      "         [-0.01451164, -0.0153533 ,  0.02227048, ..., -0.02072601,\n",
      "           0.02082429, -0.00321242],\n",
      "         [-0.0176147 ,  0.02650569,  0.03017446, ..., -0.00252109,\n",
      "          -0.01165326, -0.01810127],\n",
      "         ...,\n",
      "         [ 0.00702791,  0.02138602, -0.01645031, ...,  0.01646416,\n",
      "           0.03427608,  0.01654691],\n",
      "         [ 0.02727426, -0.0166808 ,  0.0033492 , ..., -0.001817  ,\n",
      "          -0.00580616, -0.00901036],\n",
      "         [ 0.02328181, -0.0275488 ,  0.01532976, ..., -0.00125016,\n",
      "           0.01218406, -0.01720102]]],\n",
      "\n",
      "\n",
      "       [[[ 0.0256302 , -0.02645371,  0.02830133, ...,  0.02809767,\n",
      "          -0.02214535,  0.01516677],\n",
      "         [-0.01797636,  0.01132895,  0.02932815, ..., -0.01652459,\n",
      "          -0.00097851, -0.03320619],\n",
      "         [ 0.00076389, -0.02029259,  0.00172241, ..., -0.00164964,\n",
      "          -0.0107192 ,  0.03237491],\n",
      "         ...,\n",
      "         [-0.01319446,  0.01044998, -0.030538  , ..., -0.03038442,\n",
      "          -0.0023298 , -0.03474287],\n",
      "         [-0.00093184, -0.0087288 ,  0.02651788, ...,  0.03285362,\n",
      "          -0.00974517, -0.03427181],\n",
      "         [ 0.00791658,  0.01396352, -0.03570662, ..., -0.02561593,\n",
      "           0.00788271,  0.00241129]],\n",
      "\n",
      "        [[ 0.02170737,  0.02094521, -0.01398179, ..., -0.00208616,\n",
      "           0.02121909, -0.02351211],\n",
      "         [-0.00387233, -0.00988877, -0.02080785, ..., -0.03378626,\n",
      "          -0.0163103 ,  0.00840331],\n",
      "         [ 0.00294245,  0.00070802, -0.01780885, ...,  0.02387173,\n",
      "          -0.02309873, -0.01196853],\n",
      "         ...,\n",
      "         [ 0.0264035 ,  0.01841156, -0.01165044, ...,  0.0224247 ,\n",
      "          -0.02173899,  0.03024418],\n",
      "         [-0.01574265, -0.01412633,  0.00445428, ...,  0.03399232,\n",
      "          -0.02186271,  0.0024999 ],\n",
      "         [ 0.02899151,  0.02491901, -0.00655733, ..., -0.03523764,\n",
      "          -0.00095666, -0.01982146]],\n",
      "\n",
      "        [[ 0.01748265, -0.03292449,  0.01968361, ..., -0.0257494 ,\n",
      "          -0.02118697,  0.01530334],\n",
      "         [ 0.00815194,  0.02848037, -0.03300572, ..., -0.00020487,\n",
      "           0.01083098,  0.00114509],\n",
      "         [ 0.03190766,  0.02138688,  0.02965795, ...,  0.01713367,\n",
      "          -0.00640322,  0.02859253],\n",
      "         ...,\n",
      "         [-0.02430138,  0.01439467,  0.0304459 , ..., -0.02172496,\n",
      "          -0.00594876,  0.00014009],\n",
      "         [-0.01431753,  0.0244844 , -0.03212871, ...,  0.0038418 ,\n",
      "          -0.01967597,  0.02194089],\n",
      "         [ 0.03053147,  0.01738681, -0.00689299, ...,  0.00626379,\n",
      "          -0.0289424 ,  0.03016981]]],\n",
      "\n",
      "\n",
      "       [[[-0.01794543,  0.02629183,  0.00907397, ...,  0.02851883,\n",
      "          -0.02848824,  0.03054847],\n",
      "         [ 0.01757231,  0.03530095,  0.00704636, ...,  0.01386376,\n",
      "          -0.02708658,  0.01692494],\n",
      "         [ 0.02765031,  0.0190911 , -0.00736185, ..., -0.0311906 ,\n",
      "           0.02317951,  0.03007234],\n",
      "         ...,\n",
      "         [-0.00568875, -0.0134126 ,  0.01102307, ...,  0.02721407,\n",
      "           0.01037005,  0.00998875],\n",
      "         [-0.0175004 , -0.03278001,  0.02764962, ..., -0.01419323,\n",
      "           0.02131623, -0.02924551],\n",
      "         [-0.03600926, -0.02516952, -0.02901823, ..., -0.03592118,\n",
      "          -0.02779556,  0.00087629]],\n",
      "\n",
      "        [[-0.03373674, -0.0238722 ,  0.00692287, ...,  0.00282405,\n",
      "           0.03010388, -0.00402923],\n",
      "         [ 0.00622498,  0.0305436 , -0.01337241, ...,  0.01696705,\n",
      "           0.03121372, -0.00211991],\n",
      "         [-0.01394108,  0.03561763,  0.00027466, ..., -0.01825633,\n",
      "           0.02844582,  0.00596424],\n",
      "         ...,\n",
      "         [-0.00061268,  0.03568687,  0.01859101, ..., -0.02887531,\n",
      "           0.03315297, -0.0181619 ],\n",
      "         [-0.00098149,  0.01879426,  0.01856099, ...,  0.02907982,\n",
      "           0.02262475,  0.02752902],\n",
      "         [-0.02053877,  0.02461251,  0.02175767, ...,  0.01546181,\n",
      "           0.00127692, -0.02398052]],\n",
      "\n",
      "        [[-0.02361502, -0.02122808, -0.00697352, ...,  0.02616997,\n",
      "           0.01438701,  0.01331604],\n",
      "         [-0.03398747, -0.03100808,  0.02540483, ...,  0.02140349,\n",
      "          -0.02853524, -0.02090067],\n",
      "         [ 0.0196394 , -0.02662277,  0.0162276 , ...,  0.00278609,\n",
      "          -0.00625817, -0.03584098],\n",
      "         ...,\n",
      "         [-0.01978933, -0.01622924,  0.02975583, ..., -0.01192609,\n",
      "          -0.00260501, -0.02869517],\n",
      "         [ 0.02984597,  0.00577971,  0.01448991, ...,  0.00930407,\n",
      "          -0.00071351,  0.00122045],\n",
      "         [ 0.0210628 , -0.03287899,  0.01490242, ..., -0.0064253 ,\n",
      "           0.03535102,  0.02643415]]]], dtype=float32)>, <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32)>, <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32, numpy=\n",
      "array([[[[ 6.78749569e-03,  1.44021120e-02,  2.74227057e-02, ...,\n",
      "           1.15451459e-02,  2.46117655e-02,  8.12608190e-03],\n",
      "         [ 1.98369343e-02, -2.41857022e-02,  5.89836575e-03, ...,\n",
      "           1.07719693e-02,  1.98695268e-02,  9.05317254e-03],\n",
      "         [ 2.57009454e-03,  1.75552871e-02,  1.76996309e-02, ...,\n",
      "          -2.78829150e-02, -1.93258822e-02,  1.06784087e-02],\n",
      "         ...,\n",
      "         [ 2.91637946e-02,  1.61248650e-02, -2.48270724e-02, ...,\n",
      "           9.03697126e-03,  2.43189428e-02,  7.48733245e-03],\n",
      "         [-2.60300897e-02,  9.47320834e-04,  8.61114822e-03, ...,\n",
      "           2.35643815e-02, -2.55872328e-02,  9.85508598e-03],\n",
      "         [ 5.10557927e-03,  2.66501252e-02,  1.76349226e-02, ...,\n",
      "          -1.80935860e-02, -1.01576988e-02,  6.92639314e-03]],\n",
      "\n",
      "        [[-1.85948946e-02,  1.13950297e-03, -8.46034102e-03, ...,\n",
      "          -2.46408042e-02,  1.13832112e-02, -2.39232555e-03],\n",
      "         [ 8.00145976e-03, -6.00596890e-03, -7.41778873e-03, ...,\n",
      "          -3.43397073e-03, -6.42213970e-03, -3.02142277e-03],\n",
      "         [-2.65541784e-02, -8.34150799e-03, -2.89590787e-02, ...,\n",
      "          -8.74606147e-03,  1.83527190e-02, -1.59223638e-02],\n",
      "         ...,\n",
      "         [-2.67450418e-02,  8.87490995e-03, -2.71666646e-02, ...,\n",
      "          -2.04587337e-02,  2.85276230e-02, -1.10513344e-03],\n",
      "         [-2.93135680e-02,  2.11064462e-02, -2.81525403e-03, ...,\n",
      "           1.40039455e-02, -1.56444181e-02, -2.32149195e-02],\n",
      "         [-8.78305174e-03,  2.34969091e-02,  1.45806931e-03, ...,\n",
      "          -8.67002085e-03, -1.96427070e-02,  1.61526818e-02]],\n",
      "\n",
      "        [[-9.58453678e-03,  2.15447377e-02, -6.24793954e-03, ...,\n",
      "          -2.51893662e-02,  2.36070808e-02, -5.27886488e-03],\n",
      "         [-2.91057676e-03, -7.29555637e-03, -1.67497266e-02, ...,\n",
      "          -1.39046647e-03,  2.74621975e-02, -1.92419682e-02],\n",
      "         [-1.21848006e-02, -4.01266105e-03, -3.98767553e-03, ...,\n",
      "           3.40699591e-03, -1.13041569e-02, -9.45468992e-03],\n",
      "         ...,\n",
      "         [ 2.87013128e-04, -2.66403202e-02, -6.72894157e-03, ...,\n",
      "          -2.46083997e-02,  7.33785890e-03,  2.64693853e-02],\n",
      "         [ 1.49352010e-02,  1.00805853e-02,  3.89593653e-03, ...,\n",
      "          -6.43227249e-05, -2.36782394e-02,  2.90793739e-03],\n",
      "         [-5.68505563e-03,  1.48272831e-02, -1.78251173e-02, ...,\n",
      "          -3.00544873e-03,  1.27872918e-02,  8.48821364e-03]]],\n",
      "\n",
      "\n",
      "       [[[-2.35853717e-04, -2.20553335e-02, -9.86482948e-04, ...,\n",
      "          -1.31331962e-02, -6.94552436e-04, -1.01806410e-02],\n",
      "         [-7.22650625e-03,  8.86263885e-03,  2.10196432e-02, ...,\n",
      "          -5.73739409e-03, -1.94692090e-02,  1.74560379e-02],\n",
      "         [ 9.83919017e-03, -2.58202106e-03,  2.29752008e-02, ...,\n",
      "           2.26400103e-02, -1.37896203e-02, -1.09252930e-02],\n",
      "         ...,\n",
      "         [ 7.25994818e-03, -2.56841555e-02, -9.55450721e-03, ...,\n",
      "          -3.46888229e-03,  2.16208268e-02, -7.61416554e-03],\n",
      "         [-4.19044867e-04, -1.43347820e-02, -1.86569281e-02, ...,\n",
      "           2.39307191e-02,  1.59302354e-03,  1.83906984e-02],\n",
      "         [-2.60506924e-02, -3.93069908e-03, -9.12839547e-03, ...,\n",
      "           3.05693038e-03, -8.06674547e-03,  1.42777506e-02]],\n",
      "\n",
      "        [[-1.69438906e-02, -9.94870812e-03, -2.13638172e-02, ...,\n",
      "          -6.50323927e-05, -1.96006931e-02, -1.29305832e-02],\n",
      "         [-1.48915984e-02, -3.48156877e-03,  4.11377661e-03, ...,\n",
      "          -2.00089067e-02, -2.93244980e-02,  8.85703228e-03],\n",
      "         [ 2.31956113e-02, -4.84824367e-03,  1.57091208e-03, ...,\n",
      "          -2.44505815e-02,  1.74698066e-02, -8.84509832e-03],\n",
      "         ...,\n",
      "         [-8.75619054e-03, -2.93555409e-02, -2.59761214e-02, ...,\n",
      "           8.25252198e-03, -1.38316751e-02, -2.45236568e-02],\n",
      "         [ 1.31524522e-02,  6.61592931e-04,  2.10285019e-02, ...,\n",
      "           8.77269916e-03,  1.32343173e-03, -1.74665824e-02],\n",
      "         [-1.73970871e-02,  1.00936722e-02, -2.44963877e-02, ...,\n",
      "          -2.05703937e-02, -1.19297393e-03, -2.88581867e-02]],\n",
      "\n",
      "        [[ 1.31148640e-02, -2.89727189e-03,  3.41113470e-03, ...,\n",
      "           2.73085255e-02,  1.74363684e-02, -1.47067942e-03],\n",
      "         [-1.53652309e-02,  1.10672507e-02, -2.52586138e-02, ...,\n",
      "           2.78655384e-02, -1.09000131e-03,  1.78909432e-02],\n",
      "         [ 9.11697559e-03, -1.88590288e-02, -6.92425668e-03, ...,\n",
      "           1.03557762e-02,  3.87537293e-03,  8.84099863e-03],\n",
      "         ...,\n",
      "         [ 1.83156151e-02, -2.32253652e-02,  2.11555324e-03, ...,\n",
      "          -2.55871490e-02, -2.16974728e-02,  2.35612188e-02],\n",
      "         [-2.23007128e-02, -2.51848698e-02, -2.32385155e-02, ...,\n",
      "          -1.43475644e-03,  5.88276424e-03,  2.86950339e-02],\n",
      "         [ 2.11408529e-02,  1.97445061e-02, -8.23354162e-03, ...,\n",
      "           4.63114493e-03, -9.02766548e-03, -8.51608068e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 2.00497117e-02,  2.36502849e-03, -2.48400103e-02, ...,\n",
      "           2.20048781e-02, -1.75806172e-02, -1.27199851e-03],\n",
      "         [-1.25410762e-02, -2.16622725e-02, -1.05437655e-02, ...,\n",
      "           1.87877435e-02,  2.73558069e-02,  5.07382117e-03],\n",
      "         [-7.17435591e-03, -2.01764125e-02, -1.44732064e-02, ...,\n",
      "           3.30507755e-04, -2.35222280e-03,  1.35709345e-03],\n",
      "         ...,\n",
      "         [-2.65118778e-02,  9.13885422e-03, -1.08228605e-02, ...,\n",
      "          -2.23007053e-02, -1.50200268e-02,  2.23559868e-02],\n",
      "         [-1.34511739e-02,  8.38689320e-03, -2.13791281e-02, ...,\n",
      "           2.53165495e-02,  1.83690023e-02,  2.78103296e-02],\n",
      "         [ 1.51750166e-02, -1.71051584e-02, -2.88032275e-02, ...,\n",
      "          -4.86207381e-03,  9.32547636e-03, -2.84849480e-03]],\n",
      "\n",
      "        [[ 1.38188284e-02, -1.54092535e-02, -1.36583261e-02, ...,\n",
      "          -1.04787741e-02, -2.32635066e-03,  7.62897171e-03],\n",
      "         [-1.80395320e-04,  1.68690812e-02, -1.19811762e-02, ...,\n",
      "          -2.24902686e-02,  9.61895101e-03, -4.38043475e-03],\n",
      "         [-6.65464997e-03,  2.41997223e-02, -2.52468269e-02, ...,\n",
      "           2.82847863e-02,  3.51907872e-03,  6.54187240e-03],\n",
      "         ...,\n",
      "         [-2.53178645e-02, -2.01016162e-02,  1.69762243e-02, ...,\n",
      "          -1.40623748e-03, -2.51619499e-02, -2.17607692e-02],\n",
      "         [ 6.17865659e-03, -2.70998552e-02, -1.74976364e-02, ...,\n",
      "          -6.00587763e-03, -5.21678291e-03,  2.18316261e-02],\n",
      "         [-1.49604734e-02,  1.76992882e-02, -2.60043740e-02, ...,\n",
      "          -1.68302134e-02, -2.47514602e-02, -2.21656449e-02]],\n",
      "\n",
      "        [[ 2.83416826e-02, -1.29011441e-02,  1.33490581e-02, ...,\n",
      "          -2.52916925e-02, -1.05573218e-02,  3.72126512e-03],\n",
      "         [ 7.75093772e-03,  2.59850007e-02,  1.72798205e-02, ...,\n",
      "          -1.76068395e-03,  1.08243022e-02, -4.19162400e-03],\n",
      "         [ 8.49198736e-03,  2.09500808e-02, -1.14725903e-03, ...,\n",
      "          -1.95820220e-02, -4.38204221e-03,  9.78544354e-04],\n",
      "         ...,\n",
      "         [ 2.46982556e-02, -1.62646379e-02,  3.13108787e-04, ...,\n",
      "          -1.37787312e-02, -2.56083980e-02,  1.42493658e-03],\n",
      "         [-7.11487606e-04,  2.02781614e-02,  2.37892140e-02, ...,\n",
      "           1.28826555e-02, -2.75135115e-02, -2.82428712e-02],\n",
      "         [ 1.22283306e-02,  1.41802784e-02,  2.82242894e-04, ...,\n",
      "          -1.07678529e-02,  1.55649241e-02, -1.98377483e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32, numpy=\n",
      "array([[[[ 8.42981786e-03,  3.44516709e-03,  2.52793916e-03, ...,\n",
      "          -9.33073275e-03, -1.79471746e-02,  5.79405576e-03],\n",
      "         [ 1.20803080e-02, -2.21088231e-02, -2.13249438e-02, ...,\n",
      "          -2.34820060e-02, -1.87941883e-02, -8.79704952e-04],\n",
      "         [ 8.97006318e-03,  2.35347115e-02,  5.80707192e-03, ...,\n",
      "          -2.31411904e-02,  9.77047533e-03,  2.00693496e-02],\n",
      "         ...,\n",
      "         [-8.17143731e-03, -1.48255955e-02, -1.88009962e-02, ...,\n",
      "           4.82539833e-03,  2.47246735e-02,  9.94320586e-03],\n",
      "         [-1.98774599e-02,  1.60429142e-02, -3.58697586e-03, ...,\n",
      "           2.40823291e-02, -9.31196660e-03, -1.48448739e-02],\n",
      "         [ 6.89655542e-03,  1.05036758e-02,  2.19403766e-02, ...,\n",
      "           2.20257603e-03,  6.47456571e-03,  8.19097087e-03]],\n",
      "\n",
      "        [[-1.63643435e-03,  1.56057589e-02,  5.24170324e-03, ...,\n",
      "          -2.06602085e-02,  1.06925443e-02,  1.12675466e-02],\n",
      "         [ 1.58198252e-02,  3.54457460e-03,  1.27988905e-02, ...,\n",
      "           1.99125633e-02,  2.44223438e-02,  1.76502392e-03],\n",
      "         [-1.05215907e-02, -2.02468131e-02,  3.21676955e-04, ...,\n",
      "          -4.44700755e-03, -1.43088922e-02,  1.08908117e-03],\n",
      "         ...,\n",
      "         [ 4.26788814e-03, -2.09866166e-02,  1.45122483e-02, ...,\n",
      "          -7.11939111e-03, -2.45718658e-02,  1.08953156e-02],\n",
      "         [ 1.84118785e-02, -8.57087225e-03, -1.81761533e-02, ...,\n",
      "          -1.19467853e-02,  1.01873651e-02, -3.64144146e-03],\n",
      "         [ 1.07281320e-02, -1.03380065e-02, -1.05999075e-02, ...,\n",
      "          -1.68977324e-02,  1.08456165e-02,  2.50250474e-02]],\n",
      "\n",
      "        [[ 9.74021852e-04,  4.47273999e-03,  1.95216872e-02, ...,\n",
      "           9.92269441e-03,  2.43397802e-02, -1.87695809e-02],\n",
      "         [-1.73755698e-02,  8.70767981e-03, -1.86485704e-02, ...,\n",
      "          -2.23652385e-02,  2.36213766e-02, -2.17188857e-02],\n",
      "         [ 1.23712048e-03, -2.86724046e-03,  1.20361261e-02, ...,\n",
      "          -5.51603921e-03,  5.18325903e-03,  6.35410100e-03],\n",
      "         ...,\n",
      "         [-1.01734875e-02, -1.45021612e-02, -2.40118913e-02, ...,\n",
      "          -1.04911495e-02,  7.97734037e-03, -4.25605103e-04],\n",
      "         [ 6.57721609e-03, -1.20847197e-02,  1.85494795e-02, ...,\n",
      "          -9.55138355e-04,  1.11945868e-02, -2.26120893e-02],\n",
      "         [-2.29584519e-02,  2.46123262e-02,  1.99418962e-02, ...,\n",
      "           6.66933134e-03, -7.45378807e-03,  1.46792121e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 1.22966990e-02,  7.50123337e-03,  2.27100514e-02, ...,\n",
      "           1.63165815e-02, -8.70499760e-04, -2.46253330e-02],\n",
      "         [-1.16121816e-02, -1.15198782e-02, -1.00141335e-02, ...,\n",
      "          -9.60677862e-05, -1.74943097e-02, -2.02869568e-02],\n",
      "         [-1.22090876e-02, -1.86376870e-02,  1.39165893e-02, ...,\n",
      "           1.09816380e-02,  1.60003789e-02,  8.78031552e-03],\n",
      "         ...,\n",
      "         [ 7.75013864e-03,  2.04391256e-02, -1.72472224e-02, ...,\n",
      "           1.87609345e-02, -9.57021676e-03, -1.26614533e-02],\n",
      "         [ 1.28480867e-02, -3.54256667e-03, -1.52646024e-02, ...,\n",
      "           2.25350969e-02, -4.18046489e-03,  2.76908278e-04],\n",
      "         [-2.10211761e-02,  1.15866922e-02,  3.76889482e-04, ...,\n",
      "          -8.38711858e-05, -1.77581888e-02,  1.71835348e-02]],\n",
      "\n",
      "        [[-1.11390101e-02, -1.10450834e-02, -2.71904282e-03, ...,\n",
      "          -3.28211114e-04,  3.15088779e-04, -2.47129388e-02],\n",
      "         [ 1.11030787e-03, -1.34739187e-02, -1.27610508e-02, ...,\n",
      "          -1.90013573e-02,  2.49834135e-02,  1.04151182e-02],\n",
      "         [ 1.62597150e-02,  2.13071331e-02, -1.30796190e-02, ...,\n",
      "          -7.19942339e-03,  2.78705545e-03,  1.13056228e-02],\n",
      "         ...,\n",
      "         [ 1.40281394e-03,  2.51628906e-02,  4.08725999e-03, ...,\n",
      "           1.74991786e-02,  1.50972232e-02, -4.21911106e-03],\n",
      "         [ 1.10232793e-02,  2.46037915e-02, -1.37916962e-02, ...,\n",
      "          -2.33975500e-02, -8.41614604e-03, -1.06962137e-02],\n",
      "         [ 6.27823547e-03,  1.35484524e-02,  2.05969401e-02, ...,\n",
      "           2.81700306e-03,  1.30502917e-02,  4.39846143e-03]],\n",
      "\n",
      "        [[ 3.31860781e-03,  8.72979313e-03,  1.28645226e-02, ...,\n",
      "          -7.74021633e-03, -1.36149069e-02, -1.56252068e-02],\n",
      "         [-1.02254190e-03,  1.88931413e-02,  1.84447542e-02, ...,\n",
      "          -5.17496094e-03,  1.79358013e-03,  2.42555961e-02],\n",
      "         [-1.12237334e-02,  5.86725771e-03,  1.81254968e-02, ...,\n",
      "           2.13377364e-03,  2.16560923e-02,  2.45111845e-02],\n",
      "         ...,\n",
      "         [ 1.72404349e-02, -8.53477232e-03, -1.61853023e-02, ...,\n",
      "           2.07321569e-02,  1.28885508e-02, -1.91795751e-02],\n",
      "         [ 4.64816019e-03, -1.84552111e-02,  4.16916050e-03, ...,\n",
      "           3.40956077e-03, -1.41326077e-02, -8.08231533e-03],\n",
      "         [ 2.56164186e-03, -6.75520860e-03, -8.22252594e-03, ...,\n",
      "           2.35100426e-02, -1.05685173e-02,  5.27780689e-03]]],\n",
      "\n",
      "\n",
      "       [[[-1.32018942e-02, -2.47441661e-02,  1.14201605e-02, ...,\n",
      "          -1.77444592e-02,  5.55739366e-03,  7.11467117e-03],\n",
      "         [ 1.46987773e-02,  4.09111381e-05,  1.33578107e-02, ...,\n",
      "           1.07469037e-04,  2.00247802e-02, -2.12080516e-02],\n",
      "         [ 1.94814503e-02,  1.53479613e-02,  1.08613297e-02, ...,\n",
      "          -1.69283804e-02,  1.81745589e-02,  1.71304457e-02],\n",
      "         ...,\n",
      "         [ 1.17735192e-03, -1.73239820e-02, -1.67698413e-02, ...,\n",
      "          -2.34613530e-02, -1.91049334e-02,  9.55697894e-03],\n",
      "         [ 2.53541395e-02, -2.50917263e-02,  4.72806580e-03, ...,\n",
      "          -1.62152816e-02,  1.16247013e-02, -8.96065123e-03],\n",
      "         [-5.25835901e-03, -8.14010762e-03, -3.59023735e-03, ...,\n",
      "           1.46686733e-02, -8.38750973e-04, -1.66680105e-03]],\n",
      "\n",
      "        [[ 1.24455430e-03,  9.96388495e-03, -2.87188776e-03, ...,\n",
      "           3.37378494e-03, -2.29117628e-02, -2.44136751e-02],\n",
      "         [ 2.50035189e-02,  1.50568597e-02, -2.22198889e-02, ...,\n",
      "           2.03000382e-03,  1.16568767e-02,  1.72713622e-02],\n",
      "         [-1.17443968e-02,  1.93899870e-02,  1.19997635e-02, ...,\n",
      "          -1.05120614e-03, -7.69664720e-03, -1.98387913e-03],\n",
      "         ...,\n",
      "         [-1.59511305e-02,  1.41848996e-02, -1.04247434e-02, ...,\n",
      "          -8.59909132e-03,  9.96877626e-03, -1.16033182e-02],\n",
      "         [-7.76591897e-03, -7.43573904e-03, -1.60271712e-02, ...,\n",
      "          -2.43109446e-02, -2.20604725e-02, -2.43182387e-02],\n",
      "         [ 1.64840519e-02,  1.12889111e-02, -1.26977833e-02, ...,\n",
      "           1.15587860e-02, -2.10892744e-02,  2.50226334e-02]],\n",
      "\n",
      "        [[-1.91600788e-02,  2.34749913e-02,  2.44622268e-02, ...,\n",
      "          -8.06516036e-04,  8.06270167e-03,  1.62478872e-02],\n",
      "         [ 1.05664358e-02,  4.75764833e-03,  2.14122273e-02, ...,\n",
      "           3.61181982e-03, -9.56378691e-03,  9.69741493e-03],\n",
      "         [ 1.58202648e-02,  7.08953291e-03,  1.94832683e-02, ...,\n",
      "          -3.99991497e-03,  1.15532465e-02, -3.06334347e-04],\n",
      "         ...,\n",
      "         [-3.05087864e-03,  5.06093539e-03, -1.78921223e-03, ...,\n",
      "          -1.48373852e-02, -2.08402649e-02,  2.37375125e-02],\n",
      "         [ 8.17241520e-03, -2.24592164e-03,  1.39938109e-02, ...,\n",
      "          -1.61497891e-02,  8.10766965e-03,  1.93447582e-02],\n",
      "         [-1.08992644e-02,  3.49801220e-03, -9.46575962e-03, ...,\n",
      "           8.13370943e-03,  2.90277228e-03,  1.87914819e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32, numpy=\n",
      "array([[[[-1.84665676e-02,  1.98418312e-02,  8.60146433e-03, ...,\n",
      "          -1.52505310e-02, -3.31904739e-05,  7.66566396e-03],\n",
      "         [-5.45790046e-03, -1.67718492e-02, -2.38057319e-02, ...,\n",
      "           1.20682716e-02, -7.27445632e-03, -7.35257939e-03],\n",
      "         [ 1.17798895e-02, -1.69957466e-02,  2.68279761e-03, ...,\n",
      "           2.35420838e-02,  1.14853606e-02, -1.03474595e-03],\n",
      "         ...,\n",
      "         [-7.42351636e-03, -1.12484684e-02, -9.65176523e-03, ...,\n",
      "          -1.11687947e-02, -2.25368142e-02, -3.11890244e-03],\n",
      "         [ 2.54696198e-02,  4.99323942e-03, -2.44957693e-02, ...,\n",
      "          -8.96200724e-03, -3.80359218e-03,  1.42736807e-02],\n",
      "         [-2.05132887e-02,  2.40544081e-02,  2.41551921e-02, ...,\n",
      "          -2.11828575e-03, -2.13390402e-02, -2.19108760e-02]],\n",
      "\n",
      "        [[ 1.06518343e-02,  9.17704776e-03,  7.28979334e-03, ...,\n",
      "          -1.61197037e-04, -1.41737191e-02,  3.63926217e-03],\n",
      "         [ 1.63239054e-02, -1.81830898e-02, -1.53179355e-02, ...,\n",
      "          -1.99673306e-02,  2.44883485e-02,  2.05632560e-02],\n",
      "         [ 2.07104459e-02,  1.27993338e-02, -1.72120482e-02, ...,\n",
      "           2.51307897e-02,  3.82833183e-04, -4.49519977e-03],\n",
      "         ...,\n",
      "         [-1.77402552e-02, -2.36644708e-02,  1.64106935e-02, ...,\n",
      "           1.47877857e-02, -1.46468114e-02,  2.26826556e-02],\n",
      "         [-2.44806036e-02,  2.22781412e-02, -1.13560893e-02, ...,\n",
      "           7.76091218e-03, -1.36096450e-02,  2.63240188e-04],\n",
      "         [ 7.65068829e-03, -1.86473653e-02,  9.19003040e-03, ...,\n",
      "           2.37617902e-02,  7.58220628e-03,  2.25862525e-02]],\n",
      "\n",
      "        [[-2.17323545e-02, -1.75120924e-02,  1.22944638e-02, ...,\n",
      "          -2.53717415e-03, -8.48435424e-03, -2.49916743e-02],\n",
      "         [ 5.75174019e-03,  1.94449686e-02,  1.12703182e-02, ...,\n",
      "          -1.18597224e-03, -1.35079855e-02,  2.17012130e-02],\n",
      "         [ 8.23177397e-04, -7.70257786e-04, -1.93867385e-02, ...,\n",
      "          -2.38213670e-02,  4.84181568e-04,  1.81024969e-02],\n",
      "         ...,\n",
      "         [ 1.91326439e-03, -2.36513838e-02, -1.38391927e-03, ...,\n",
      "           2.42124796e-02,  1.29279979e-02,  6.71561807e-04],\n",
      "         [ 1.93887204e-02, -4.98665124e-03,  1.16676092e-05, ...,\n",
      "           2.29619481e-02,  1.00470632e-02, -7.54280016e-03],\n",
      "         [-2.41964366e-02,  1.68654472e-02, -2.37296112e-02, ...,\n",
      "           1.29056647e-02, -2.48476919e-02,  1.36691704e-02]]],\n",
      "\n",
      "\n",
      "       [[[-1.84542984e-02,  1.91861838e-02, -1.72633976e-02, ...,\n",
      "          -1.62007175e-02, -1.75917242e-02, -2.38260925e-02],\n",
      "         [ 1.15455687e-03, -9.93590802e-04, -1.48225017e-03, ...,\n",
      "           2.36527063e-03,  1.96594857e-02, -1.70878749e-02],\n",
      "         [ 2.15623528e-02, -1.68116223e-02,  3.02119181e-03, ...,\n",
      "          -1.69707648e-02, -6.06601872e-03,  2.82784924e-04],\n",
      "         ...,\n",
      "         [ 9.81456786e-03, -1.19832549e-02, -9.77018476e-03, ...,\n",
      "           2.45013647e-02, -1.73880719e-02, -2.13193055e-02],\n",
      "         [ 3.24852206e-03,  2.29974166e-02, -2.02525742e-02, ...,\n",
      "          -1.66012831e-02, -7.20497780e-03, -8.56459886e-03],\n",
      "         [-1.93427987e-02, -1.92879140e-02, -1.57846995e-02, ...,\n",
      "          -2.19140276e-02,  1.59295090e-02, -7.49938190e-03]],\n",
      "\n",
      "        [[ 6.60633668e-03, -2.18706112e-02, -1.55210169e-02, ...,\n",
      "           8.29496607e-03,  1.14428513e-02,  1.17641017e-02],\n",
      "         [ 1.89144164e-04,  4.46305424e-03, -1.80265829e-02, ...,\n",
      "          -2.26488449e-02, -2.10668333e-02,  1.08462125e-02],\n",
      "         [ 2.23398767e-02, -5.76978736e-03,  3.74350138e-03, ...,\n",
      "           1.79552920e-02, -6.08628616e-04,  2.44043954e-02],\n",
      "         ...,\n",
      "         [-6.90210424e-03,  2.40721591e-02, -2.35167779e-02, ...,\n",
      "          -2.37315875e-02, -2.07264256e-02,  6.44622371e-03],\n",
      "         [ 9.45027918e-04, -1.42343221e-02,  2.04268917e-02, ...,\n",
      "           4.92254458e-03, -1.47078335e-02, -4.97127883e-03],\n",
      "         [ 2.49627046e-02, -1.93483159e-02,  1.34787522e-03, ...,\n",
      "           9.01300460e-03, -8.15108791e-03, -2.18822248e-02]],\n",
      "\n",
      "        [[-2.35195830e-02,  1.22702979e-02,  1.31945647e-02, ...,\n",
      "          -1.56530142e-02, -1.94521043e-02,  1.79361589e-02],\n",
      "         [-1.63075849e-02,  1.17565505e-03, -8.24672543e-03, ...,\n",
      "          -1.44317700e-02, -2.58278102e-03,  2.27998570e-02],\n",
      "         [-4.77574766e-04,  5.93160093e-03,  2.03518644e-02, ...,\n",
      "          -2.19914988e-02, -1.94568373e-02,  8.11515376e-03],\n",
      "         ...,\n",
      "         [-4.84306365e-05, -9.91824735e-03, -1.03983106e-02, ...,\n",
      "           1.46084726e-02, -2.10141633e-02,  2.41506211e-02],\n",
      "         [-1.87523160e-02, -2.18507610e-02,  2.53884420e-02, ...,\n",
      "          -6.49418682e-04, -1.19603574e-02, -2.28390787e-02],\n",
      "         [ 1.15443505e-02, -1.59468651e-02, -1.49992816e-02, ...,\n",
      "          -1.43340044e-02, -1.15688071e-02, -8.05677846e-03]]],\n",
      "\n",
      "\n",
      "       [[[-4.47568484e-03,  1.16917863e-02, -3.52787040e-03, ...,\n",
      "          -1.35865463e-02, -8.45882110e-03, -6.43411092e-03],\n",
      "         [ 1.99734457e-02, -2.18201187e-02, -1.64488163e-02, ...,\n",
      "           7.63113052e-03,  1.64555945e-03, -1.80179849e-02],\n",
      "         [-2.14560051e-02, -1.05440058e-03,  6.28633425e-03, ...,\n",
      "           2.12309882e-02, -9.92257241e-03,  2.18867697e-03],\n",
      "         ...,\n",
      "         [-7.20204785e-04,  1.65197365e-02,  8.70323926e-03, ...,\n",
      "           4.48925048e-03,  2.25905962e-02,  2.05525495e-02],\n",
      "         [-1.03771957e-02, -2.31860857e-02, -8.26508366e-03, ...,\n",
      "           2.28666104e-02,  1.50955282e-03, -2.03015022e-02],\n",
      "         [ 2.02485882e-02, -2.39000190e-02, -9.95330513e-04, ...,\n",
      "          -1.61139816e-02, -6.90192170e-03,  1.55919306e-02]],\n",
      "\n",
      "        [[-1.44084711e-02, -8.82522948e-03,  1.92926601e-02, ...,\n",
      "           2.24443711e-02, -1.13355154e-02,  9.68760252e-03],\n",
      "         [-2.11950652e-02, -9.09375027e-03, -8.88409093e-04, ...,\n",
      "          -5.40058874e-03, -1.79976858e-02,  7.56464526e-03],\n",
      "         [ 1.83685757e-02, -3.24511901e-04,  1.04833692e-02, ...,\n",
      "          -1.28293550e-02, -7.96837360e-03,  1.08401217e-02],\n",
      "         ...,\n",
      "         [ 2.19561011e-02, -7.70052895e-03, -1.24108614e-02, ...,\n",
      "          -5.23431227e-04,  1.83450095e-02,  1.66051388e-02],\n",
      "         [-2.34193038e-02, -3.05353105e-03,  2.35155374e-02, ...,\n",
      "           2.13056765e-02, -9.99423489e-03,  2.45935060e-02],\n",
      "         [-1.25312619e-03,  3.36650200e-03, -1.76755469e-02, ...,\n",
      "          -1.96421314e-02,  1.38868280e-02, -2.48361211e-02]],\n",
      "\n",
      "        [[ 1.94808543e-02,  2.12669745e-02, -2.37846710e-02, ...,\n",
      "          -2.14150585e-02,  9.50599462e-03,  1.00743584e-02],\n",
      "         [-2.98539177e-03,  1.01002268e-02, -1.46093620e-02, ...,\n",
      "          -9.23314318e-03, -4.48463857e-03,  6.00410625e-03],\n",
      "         [ 1.57547891e-02,  6.55367970e-03, -2.38980539e-03, ...,\n",
      "          -1.97418444e-02,  1.31774582e-02,  6.96072355e-03],\n",
      "         ...,\n",
      "         [-2.19008271e-02,  2.11934783e-02,  2.27862075e-02, ...,\n",
      "           8.55578482e-03,  1.14809200e-02, -2.00614892e-02],\n",
      "         [ 7.82807916e-03, -3.78556550e-04,  1.05651841e-03, ...,\n",
      "          -7.36210495e-03,  6.21701404e-03, -1.62712056e-02],\n",
      "         [ 2.28207074e-02,  9.19915736e-03,  3.78103554e-03, ...,\n",
      "          -1.36908153e-02, -4.99433465e-03,  1.17057562e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32, numpy=\n",
      "array([[[[-0.01809764,  0.02242779,  0.00886652, ..., -0.00767691,\n",
      "          -0.00616783,  0.01608438],\n",
      "         [ 0.01267383, -0.00132211,  0.00699085, ...,  0.00901647,\n",
      "          -0.00079425, -0.0135325 ],\n",
      "         [-0.01705906, -0.0116753 ,  0.01986949, ..., -0.01747251,\n",
      "          -0.00180287,  0.00597929],\n",
      "         ...,\n",
      "         [ 0.01182893, -0.02350905,  0.02343543, ...,  0.01264252,\n",
      "          -0.00103569,  0.00195604],\n",
      "         [ 0.00168928,  0.01509438,  0.02478045, ...,  0.0156348 ,\n",
      "          -0.00329124, -0.01357687],\n",
      "         [ 0.02113394, -0.01545083, -0.00740418, ..., -0.00979064,\n",
      "           0.02092852, -0.02180406]],\n",
      "\n",
      "        [[ 0.01487586,  0.02132642,  0.02302977, ...,  0.0231768 ,\n",
      "           0.01398587,  0.00761473],\n",
      "         [ 0.00188244, -0.01131967,  0.00961319, ..., -0.02400276,\n",
      "          -0.00138178,  0.02350949],\n",
      "         [-0.0044651 , -0.01372757,  0.00067235, ..., -0.02232772,\n",
      "           0.02070695,  0.02343649],\n",
      "         ...,\n",
      "         [ 0.00770859,  0.00731928,  0.00181839, ...,  0.02109288,\n",
      "          -0.0247246 ,  0.00955475],\n",
      "         [-0.0047619 ,  0.0030383 ,  0.0083838 , ..., -0.00816722,\n",
      "           0.0042171 , -0.02219137],\n",
      "         [-0.00640262,  0.01723155,  0.02271756, ..., -0.00345708,\n",
      "           0.01187198,  0.00093889]],\n",
      "\n",
      "        [[-0.01513038,  0.02218816, -0.00372738, ..., -0.00545235,\n",
      "          -0.00622514, -0.00582212],\n",
      "         [ 0.01908562,  0.00922661,  0.01862716, ..., -0.00322446,\n",
      "           0.01641635, -0.00802035],\n",
      "         [-0.00588591, -0.01805   ,  0.0079949 , ...,  0.00503897,\n",
      "          -0.00568171, -0.00410798],\n",
      "         ...,\n",
      "         [ 0.0218582 , -0.00208552, -0.01283057, ...,  0.0104078 ,\n",
      "          -0.01628183, -0.0066342 ],\n",
      "         [-0.01931696,  0.01557469, -0.01687776, ...,  0.02440606,\n",
      "           0.01177999,  0.00837225],\n",
      "         [ 0.01613756, -0.01407376, -0.01923921, ..., -0.0035139 ,\n",
      "           0.01126532,  0.01972431]]],\n",
      "\n",
      "\n",
      "       [[[ 0.0074477 ,  0.00690717,  0.00366923, ..., -0.02346801,\n",
      "          -0.02198129, -0.01276709],\n",
      "         [ 0.01468588,  0.01892857,  0.01137244, ..., -0.01251163,\n",
      "           0.00187975, -0.01492312],\n",
      "         [ 0.00266663,  0.02362083,  0.02240398, ...,  0.01658778,\n",
      "          -0.00850803, -0.01009413],\n",
      "         ...,\n",
      "         [-0.00142161,  0.00055541, -0.00098649, ...,  0.02042807,\n",
      "          -0.01954015, -0.0011278 ],\n",
      "         [ 0.00424278, -0.00666718,  0.02093871, ..., -0.02350007,\n",
      "           0.01694655,  0.007698  ],\n",
      "         [ 0.018658  ,  0.01700614, -0.01812839, ..., -0.02169287,\n",
      "          -0.0227023 ,  0.00650796]],\n",
      "\n",
      "        [[ 0.00906407, -0.01623009, -0.02066065, ..., -0.01361957,\n",
      "          -0.00019359, -0.00788975],\n",
      "         [ 0.01460072,  0.01706299,  0.00189084, ..., -0.01730994,\n",
      "          -0.00956689,  0.00696874],\n",
      "         [ 0.00919821, -0.01977889,  0.01144605, ...,  0.01063244,\n",
      "           0.01001649,  0.009006  ],\n",
      "         ...,\n",
      "         [-0.0097263 ,  0.0197823 , -0.02420011, ...,  0.01370613,\n",
      "           0.00264613,  0.00061532],\n",
      "         [-0.01409302, -0.00485332, -0.01723165, ..., -0.02320761,\n",
      "          -0.00088384,  0.0074021 ],\n",
      "         [ 0.00864823, -0.00910766, -0.01840764, ...,  0.0062895 ,\n",
      "           0.0033858 , -0.00297754]],\n",
      "\n",
      "        [[-0.0008202 ,  0.02398043,  0.01165932, ..., -0.00301881,\n",
      "           0.00096805,  0.00176572],\n",
      "         [ 0.00169431,  0.00661931,  0.00977151, ..., -0.01215083,\n",
      "          -0.01605999,  0.00472679],\n",
      "         [ 0.01811284,  0.02038161,  0.02029165, ...,  0.0013176 ,\n",
      "          -0.01360905, -0.02431447],\n",
      "         ...,\n",
      "         [-0.01650818,  0.00274477, -0.01809639, ..., -0.02075182,\n",
      "          -0.00038864, -0.01466992],\n",
      "         [ 0.00699353, -0.01006197,  0.0115515 , ...,  0.0198012 ,\n",
      "           0.02113587,  0.0176988 ],\n",
      "         [-0.02012418,  0.00449665,  0.00125479, ..., -0.00317625,\n",
      "          -0.0008467 ,  0.01337167]]],\n",
      "\n",
      "\n",
      "       [[[-0.0008243 ,  0.01623463,  0.01527682, ..., -0.01412401,\n",
      "           0.00319661,  0.00603645],\n",
      "         [-0.01060697, -0.01330733, -0.00015418, ..., -0.00949961,\n",
      "          -0.02501117,  0.01863423],\n",
      "         [ 0.00055909, -0.0049478 ,  0.02165607, ..., -0.00054363,\n",
      "           0.01775287,  0.02337908],\n",
      "         ...,\n",
      "         [ 0.01691484,  0.02461255,  0.00278437, ..., -0.00245349,\n",
      "          -0.00342387, -0.01952015],\n",
      "         [ 0.00896408, -0.02184794,  0.02027854, ..., -0.01356818,\n",
      "          -0.01674252, -0.02093722],\n",
      "         [-0.00244907, -0.00903501, -0.0023344 , ..., -0.02291816,\n",
      "           0.01259343, -0.00891436]],\n",
      "\n",
      "        [[ 0.00686124, -0.01201994, -0.01867587, ..., -0.0021934 ,\n",
      "           0.00569549, -0.01764049],\n",
      "         [-0.01885796, -0.01416137,  0.01969159, ..., -0.00181456,\n",
      "          -0.00501445,  0.02425735],\n",
      "         [ 0.00559676, -0.01109021, -0.01483032, ...,  0.00178552,\n",
      "          -0.01380562,  0.01955642],\n",
      "         ...,\n",
      "         [-0.0219685 ,  0.0133974 ,  0.0032859 , ...,  0.01434247,\n",
      "          -0.01195603, -0.0203515 ],\n",
      "         [-0.02423284,  0.00269781,  0.01573031, ..., -0.00480247,\n",
      "           0.01554001,  0.01961674],\n",
      "         [-0.00054682, -0.00438536,  0.01082961, ...,  0.00668047,\n",
      "          -0.01973562,  0.0240941 ]],\n",
      "\n",
      "        [[-0.00575923,  0.01893995, -0.0211374 , ..., -0.01717179,\n",
      "          -0.01507561,  0.0122379 ],\n",
      "         [ 0.00278987, -0.00335014, -0.01837628, ..., -0.01649029,\n",
      "          -0.02029665, -0.01905692],\n",
      "         [ 0.01214381,  0.00560725, -0.01111622, ..., -0.00637299,\n",
      "          -0.000686  , -0.01478098],\n",
      "         ...,\n",
      "         [-0.00764201, -0.01084288,  0.0118462 , ...,  0.0209298 ,\n",
      "           0.0146638 ,  0.02541535],\n",
      "         [ 0.00163309, -0.01550799,  0.00072916, ..., -0.016603  ,\n",
      "           0.01441953, -0.01236894],\n",
      "         [ 0.01011558, -0.00450548,  0.00825009, ...,  0.01354339,\n",
      "          -0.01661931,  0.01355588]]]], dtype=float32)>, <tf.Variable 'block5_conv1/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32, numpy=\n",
      "array([[[[-2.29831561e-02, -1.77266411e-02, -1.24669010e-02, ...,\n",
      "          -2.03088876e-02, -5.03111444e-03,  9.29052383e-03],\n",
      "         [-1.74155384e-02,  7.60139525e-03,  2.01082714e-02, ...,\n",
      "          -2.50275657e-02, -5.99369220e-03,  1.29836947e-02],\n",
      "         [ 1.26631856e-02,  4.37461585e-03,  2.48041973e-02, ...,\n",
      "          -3.92690860e-03,  1.52671896e-02,  6.57497719e-03],\n",
      "         ...,\n",
      "         [ 2.21288316e-02, -1.04033016e-03,  2.97453254e-03, ...,\n",
      "          -2.37830952e-02,  5.72588481e-03, -9.90420114e-03],\n",
      "         [-2.50423662e-02,  1.48766227e-02,  1.97321847e-02, ...,\n",
      "          -2.15094164e-02,  3.35660577e-03, -2.50829495e-02],\n",
      "         [ 2.39747390e-02,  5.14515303e-03, -2.81029940e-03, ...,\n",
      "          -1.97152980e-03,  1.93768367e-02,  9.51580703e-03]],\n",
      "\n",
      "        [[-2.24336945e-02,  2.00132430e-02, -2.46209595e-02, ...,\n",
      "          -1.13812620e-02,  2.45961584e-02,  1.51156038e-02],\n",
      "         [-1.71643607e-02,  1.49828941e-02,  8.47504660e-03, ...,\n",
      "           2.22801119e-02, -6.64821453e-03, -6.31085597e-03],\n",
      "         [-2.28226166e-02,  1.95616968e-02,  1.53526105e-03, ...,\n",
      "           8.18100199e-03,  2.42033228e-02, -2.55025607e-02],\n",
      "         ...,\n",
      "         [-1.25517696e-03, -2.35555470e-02,  1.46151893e-03, ...,\n",
      "           1.14256516e-02,  2.30993181e-02,  2.49284543e-02],\n",
      "         [ 3.49752046e-03, -1.10226413e-02, -1.16375731e-02, ...,\n",
      "          -1.47029301e-02,  5.92377782e-03,  4.62917425e-03],\n",
      "         [ 2.25884318e-02, -8.79057311e-03,  1.00505054e-02, ...,\n",
      "          -5.50084189e-03, -2.63927504e-04,  1.04570687e-02]],\n",
      "\n",
      "        [[-2.52378620e-02,  4.03877348e-05, -1.80085264e-02, ...,\n",
      "          -2.30810009e-02,  1.47492141e-02,  2.03875192e-02],\n",
      "         [-2.27577426e-02,  2.45449916e-02,  8.09971243e-03, ...,\n",
      "           2.52647512e-02, -3.68951075e-03,  2.22501047e-02],\n",
      "         [ 1.79169476e-02,  8.45231861e-03,  1.40534937e-02, ...,\n",
      "          -3.46083194e-03,  9.29132104e-04,  1.80558562e-02],\n",
      "         ...,\n",
      "         [-9.92540177e-03,  1.59260221e-02, -3.84053029e-03, ...,\n",
      "          -6.37181103e-03,  1.33065172e-02, -1.39753167e-02],\n",
      "         [ 6.93636015e-03,  1.46417618e-02, -1.93078499e-02, ...,\n",
      "          -1.86600313e-02,  1.57380365e-02,  3.03518958e-03],\n",
      "         [-6.30190037e-03,  3.40898335e-03,  3.78480181e-03, ...,\n",
      "           2.03181766e-02,  2.10211053e-03, -8.26835074e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 2.48251706e-02,  1.73000805e-02, -1.99259259e-02, ...,\n",
      "          -1.48005076e-02, -2.23030299e-02,  2.39949189e-02],\n",
      "         [-9.10193846e-03,  1.52813867e-02,  1.93229318e-02, ...,\n",
      "          -8.91735032e-03,  1.31009296e-02, -2.26835441e-02],\n",
      "         [ 2.21691765e-02,  1.92464851e-02, -1.08312285e-02, ...,\n",
      "           3.67125496e-03, -1.62266027e-02,  7.11787492e-03],\n",
      "         ...,\n",
      "         [ 1.81404091e-02, -1.63385496e-02,  1.12842321e-02, ...,\n",
      "           2.71782652e-03,  5.02450764e-03, -2.40395404e-03],\n",
      "         [ 3.52941453e-03,  2.28813440e-02,  2.30967104e-02, ...,\n",
      "           1.45077407e-02,  3.76507826e-03, -1.97607689e-02],\n",
      "         [-1.86198633e-02, -3.76746990e-03,  2.39604376e-02, ...,\n",
      "           1.65961906e-02,  2.52676383e-02, -1.59558021e-02]],\n",
      "\n",
      "        [[ 1.70892663e-02,  1.82062387e-04,  6.65952265e-03, ...,\n",
      "           2.01077275e-02,  1.38692483e-02, -2.32897140e-03],\n",
      "         [-8.14611837e-03, -2.16566585e-02, -2.11461112e-02, ...,\n",
      "          -1.04712928e-02, -7.69645348e-03,  9.31531936e-03],\n",
      "         [ 4.39584628e-03,  2.07207575e-02, -8.39722715e-03, ...,\n",
      "          -1.58308242e-02, -3.20945494e-03,  7.93557614e-04],\n",
      "         ...,\n",
      "         [-1.02142161e-02, -1.84583124e-02, -4.05652076e-03, ...,\n",
      "          -1.73094496e-03,  1.09668374e-02, -2.48775259e-03],\n",
      "         [ 2.43489295e-02, -2.23824419e-02, -4.14314866e-03, ...,\n",
      "           9.29839909e-03, -1.64498985e-02,  1.77763551e-02],\n",
      "         [-3.52917798e-03,  8.24569166e-03, -3.52880172e-03, ...,\n",
      "          -2.94736959e-03,  9.80519503e-03,  5.17568551e-03]],\n",
      "\n",
      "        [[-2.74908915e-03,  9.54943150e-03,  2.12729871e-02, ...,\n",
      "          -1.27350744e-02, -2.41834670e-02,  1.54797547e-03],\n",
      "         [-1.80125423e-02,  1.41056441e-03,  6.06921315e-03, ...,\n",
      "           2.51671374e-02,  1.20635368e-02, -1.22178178e-02],\n",
      "         [-7.69120269e-03,  9.82357934e-03,  7.26855919e-03, ...,\n",
      "           1.12912767e-02, -1.78700872e-03, -1.20725827e-02],\n",
      "         ...,\n",
      "         [-6.79801777e-03, -1.15102418e-02, -2.36168746e-02, ...,\n",
      "           1.08931400e-02, -1.61405839e-02, -6.07803278e-03],\n",
      "         [ 1.45124309e-02, -7.03200884e-03,  2.16389671e-02, ...,\n",
      "          -2.00960003e-02,  1.90727636e-02,  1.96914673e-02],\n",
      "         [-1.18711926e-02, -1.07309315e-02,  1.82259269e-02, ...,\n",
      "          -1.52617861e-02, -1.85329504e-02, -7.28395768e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 1.37420967e-02, -2.48378012e-02,  6.08704239e-03, ...,\n",
      "           2.28494927e-02, -1.33215422e-02, -2.43891031e-02],\n",
      "         [-4.40059789e-03,  1.50484592e-02, -1.31635740e-03, ...,\n",
      "          -1.55952200e-03,  7.60207698e-03,  1.74134076e-02],\n",
      "         [-2.04809569e-03, -7.64618069e-03, -2.23196801e-02, ...,\n",
      "          -2.10909955e-02, -3.90113331e-03,  4.52837162e-03],\n",
      "         ...,\n",
      "         [-1.22506618e-02,  4.48110513e-03,  1.99726149e-02, ...,\n",
      "           1.01775825e-02, -2.43901499e-02, -1.59950182e-03],\n",
      "         [-6.57577440e-03, -1.17734512e-02, -1.04537001e-02, ...,\n",
      "          -8.45004991e-03, -1.23454714e-02,  1.23845488e-02],\n",
      "         [ 2.49525867e-02,  2.06889212e-02,  1.29047595e-02, ...,\n",
      "           2.44774334e-02,  2.16360800e-02, -1.77934729e-02]],\n",
      "\n",
      "        [[-2.31868289e-02, -1.30455643e-02,  2.45403051e-02, ...,\n",
      "          -1.01175755e-02, -6.12062216e-03, -2.05263607e-02],\n",
      "         [-6.48689643e-03, -2.41892152e-02, -1.03780469e-02, ...,\n",
      "          -1.32394414e-02,  1.59307458e-02, -2.18551960e-02],\n",
      "         [ 2.44678706e-02, -7.73075782e-03, -1.25720892e-02, ...,\n",
      "          -1.82687249e-02, -1.82944387e-02,  1.52366310e-02],\n",
      "         ...,\n",
      "         [ 1.90356746e-03,  1.46892183e-02,  1.90698393e-02, ...,\n",
      "          -6.18741848e-03, -2.45263018e-02, -2.13115104e-03],\n",
      "         [-5.85401244e-03,  3.07282247e-03, -1.86289214e-02, ...,\n",
      "          -2.30587795e-02,  1.87595859e-02,  2.32888758e-02],\n",
      "         [ 1.19870380e-02,  5.34727424e-03,  1.51371956e-03, ...,\n",
      "          -1.66754890e-02,  7.84051418e-03,  1.12631097e-02]],\n",
      "\n",
      "        [[ 1.81208551e-02, -1.39611540e-02,  1.62806734e-02, ...,\n",
      "           9.55871865e-03, -1.65140554e-02, -1.89973973e-03],\n",
      "         [-1.72637925e-02,  1.87978372e-02, -8.79925862e-03, ...,\n",
      "           1.10722333e-02, -1.92291122e-02, -2.51299907e-02],\n",
      "         [-9.31322575e-04,  1.49630122e-02,  2.65396945e-03, ...,\n",
      "          -1.74199790e-02,  5.77586517e-03,  1.36863515e-02],\n",
      "         ...,\n",
      "         [ 2.27635875e-02,  7.56267458e-03,  1.89060681e-02, ...,\n",
      "           9.19499621e-03,  1.66855492e-02, -1.49467960e-04],\n",
      "         [-3.24882008e-03,  1.16915889e-02, -4.30638902e-03, ...,\n",
      "           2.02319697e-02, -2.44377591e-02, -1.66670829e-02],\n",
      "         [ 2.49111727e-02, -7.42647238e-03, -1.49780754e-02, ...,\n",
      "          -7.94185139e-03, -1.40381642e-02,  1.34345777e-02]]]],\n",
      "      dtype=float32)>, <tf.Variable 'block5_conv2/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32, numpy=\n",
      "array([[[[ 0.01877018,  0.01705515,  0.01232395, ..., -0.00735322,\n",
      "          -0.00655289, -0.00609743],\n",
      "         [ 0.00609396, -0.0211968 ,  0.00541429, ..., -0.00024388,\n",
      "          -0.01062838,  0.02092905],\n",
      "         [ 0.01945272, -0.02444153,  0.01723463, ..., -0.01051052,\n",
      "           0.00210111,  0.00222642],\n",
      "         ...,\n",
      "         [-0.00316893,  0.01923077, -0.02307581, ...,  0.00921701,\n",
      "           0.00314717,  0.00871142],\n",
      "         [-0.00189474, -0.00690252, -0.02442155, ...,  0.02095631,\n",
      "           0.00963125,  0.01991245],\n",
      "         [-0.01344204, -0.0081538 ,  0.02098158, ...,  0.00779562,\n",
      "          -0.0167457 ,  0.01690019]],\n",
      "\n",
      "        [[ 0.00771328, -0.02403547, -0.00582647, ..., -0.01549387,\n",
      "           0.00930484, -0.02442145],\n",
      "         [-0.01941081, -0.00108426, -0.0212284 , ..., -0.02319797,\n",
      "           0.02542645, -0.0050514 ],\n",
      "         [ 0.01585333, -0.00647504, -0.00603054, ..., -0.01693008,\n",
      "          -0.01359556, -0.00747759],\n",
      "         ...,\n",
      "         [ 0.00265759, -0.00185516, -0.00832416, ...,  0.00503605,\n",
      "           0.01663907,  0.00966108],\n",
      "         [-0.00015981,  0.01287455, -0.01395494, ...,  0.01735593,\n",
      "           0.00481768, -0.01010625],\n",
      "         [ 0.00146242,  0.01409502, -0.02176801, ..., -0.0180457 ,\n",
      "          -0.01218174, -0.00655776]],\n",
      "\n",
      "        [[-0.01801645, -0.00631434, -0.00922715, ...,  0.02447547,\n",
      "           0.01734819, -0.00061899],\n",
      "         [-0.0175862 ,  0.00346686,  0.0100054 , ..., -0.00865682,\n",
      "          -0.02494958,  0.00620577],\n",
      "         [ 0.00652234,  0.01929012, -0.01426483, ...,  0.02392472,\n",
      "           0.02303744,  0.02257598],\n",
      "         ...,\n",
      "         [-0.02214937, -0.01649135, -0.00410136, ...,  0.00458989,\n",
      "          -0.00265876,  0.00764321],\n",
      "         [ 0.01557091,  0.01140741, -0.02024647, ...,  0.0064309 ,\n",
      "           0.00961966, -0.01184029],\n",
      "         [-0.01792441, -0.01845055, -0.01109812, ...,  0.00033469,\n",
      "          -0.01878587, -0.00367205]]],\n",
      "\n",
      "\n",
      "       [[[-0.02238816,  0.01337335,  0.01095207, ...,  0.01909469,\n",
      "          -0.02275104,  0.02421938],\n",
      "         [ 0.01779778,  0.02332353,  0.02351503, ...,  0.00963689,\n",
      "           0.01973275, -0.01671079],\n",
      "         [ 0.01636967, -0.01092848,  0.01291221, ...,  0.0141905 ,\n",
      "           0.01893554, -0.01114217],\n",
      "         ...,\n",
      "         [-0.02345045, -0.01072428, -0.02399084, ...,  0.01779743,\n",
      "           0.02488388,  0.0013147 ],\n",
      "         [ 0.0023244 ,  0.0044031 , -0.02194725, ..., -0.02118949,\n",
      "          -0.00482967,  0.01792146],\n",
      "         [-0.01249911, -0.0203108 ,  0.01349214, ..., -0.00981313,\n",
      "          -0.01356291,  0.0033802 ]],\n",
      "\n",
      "        [[ 0.00558901, -0.01463488, -0.02331752, ...,  0.00762583,\n",
      "          -0.01807657,  0.0242256 ],\n",
      "         [-0.00044249,  0.02396696,  0.01906383, ..., -0.02051241,\n",
      "          -0.00155611, -0.00811691],\n",
      "         [ 0.00728556,  0.013087  ,  0.00789218, ...,  0.00152629,\n",
      "           0.00729508,  0.01267269],\n",
      "         ...,\n",
      "         [ 0.0245523 ,  0.00945159,  0.02273992, ...,  0.02014722,\n",
      "          -0.0233585 , -0.02084136],\n",
      "         [ 0.00447772,  0.01116123,  0.02144861, ...,  0.02159618,\n",
      "           0.00948148,  0.00423936],\n",
      "         [-0.02013656,  0.01280567, -0.02185697, ...,  0.01660631,\n",
      "          -0.01090841,  0.02551059]],\n",
      "\n",
      "        [[-0.00804686, -0.01242009,  0.00145787, ..., -0.01001321,\n",
      "          -0.0109197 ,  0.00042193],\n",
      "         [-0.0074692 ,  0.01665195, -0.01129592, ...,  0.02490582,\n",
      "           0.00615655,  0.02180832],\n",
      "         [-0.00896298, -0.00781609, -0.01433925, ..., -0.022227  ,\n",
      "           0.00210937, -0.02112067],\n",
      "         ...,\n",
      "         [-0.02506902, -0.01053813,  0.00280232, ..., -0.01882624,\n",
      "           0.00076154, -0.02327334],\n",
      "         [ 0.00427404,  0.01116619, -0.01570114, ...,  0.00313405,\n",
      "          -0.00575897, -0.00946358],\n",
      "         [-0.00623083,  0.01339686,  0.02039783, ...,  0.01672855,\n",
      "           0.02341488, -0.01902233]]],\n",
      "\n",
      "\n",
      "       [[[-0.0125088 , -0.00036298, -0.00289513, ...,  0.01973432,\n",
      "           0.00140553,  0.00557119],\n",
      "         [ 0.00996355, -0.01539123,  0.00632112, ...,  0.01820941,\n",
      "           0.00074991,  0.02310268],\n",
      "         [-0.0019702 ,  0.00603409, -0.0098899 , ...,  0.0021316 ,\n",
      "          -0.01935366,  0.01821918],\n",
      "         ...,\n",
      "         [-0.01567201, -0.01825024, -0.00965799, ..., -0.01335773,\n",
      "           0.00821318, -0.0247399 ],\n",
      "         [-0.01147801, -0.00800604,  0.02202042, ...,  0.01253463,\n",
      "          -0.02025002, -0.0001915 ],\n",
      "         [ 0.0250283 , -0.0248584 , -0.00819065, ..., -0.01245849,\n",
      "          -0.00182453,  0.00089041]],\n",
      "\n",
      "        [[ 0.01391239, -0.01274388,  0.0033457 , ..., -0.01347343,\n",
      "           0.02525355, -0.01843224],\n",
      "         [ 0.00460789,  0.01087674,  0.00231371, ..., -0.01782716,\n",
      "           0.00868867,  0.01708759],\n",
      "         [ 0.02047607,  0.02099156, -0.0071997 , ..., -0.00635033,\n",
      "           0.0206949 ,  0.00169346],\n",
      "         ...,\n",
      "         [-0.02021702,  0.01592225, -0.01527173, ..., -0.02210076,\n",
      "           0.00570511, -0.0210065 ],\n",
      "         [ 0.00097841, -0.00776627, -0.01191057, ..., -0.0183642 ,\n",
      "          -0.01398996,  0.00719621],\n",
      "         [-0.01186743,  0.00884537,  0.02064893, ...,  0.0104811 ,\n",
      "          -0.00555626,  0.01999994]],\n",
      "\n",
      "        [[-0.00264028, -0.00888923, -0.02527032, ..., -0.00854049,\n",
      "           0.00246541,  0.01626797],\n",
      "         [ 0.02144547, -0.02126993,  0.00579046, ...,  0.02330427,\n",
      "          -0.01319126,  0.02101265],\n",
      "         [ 0.01082525, -0.01219348, -0.00665723, ..., -0.00227557,\n",
      "          -0.01255923,  0.01782751],\n",
      "         ...,\n",
      "         [ 0.00980867,  0.00115825, -0.02522699, ..., -0.01040744,\n",
      "           0.01760566, -0.01779818],\n",
      "         [ 0.01844869,  0.00395097, -0.02286625, ..., -0.00767841,\n",
      "           0.00262086, -0.02197372],\n",
      "         [ 0.00368381, -0.01813647,  0.02364691, ...,  0.00323106,\n",
      "          -0.00441597, -0.0046093 ]]]], dtype=float32)>, <tf.Variable 'block5_conv3/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0.], dtype=float32)>, <tf.Variable 'fc1/kernel:0' shape=(25088, 4096) dtype=float32, numpy=\n",
      "array([[-0.00556265, -0.01295168, -0.01084562, ..., -0.0106333 ,\n",
      "        -0.0031338 ,  0.00313129],\n",
      "       [ 0.01192098, -0.00425294, -0.00463449, ...,  0.00095637,\n",
      "         0.01076267,  0.01194124],\n",
      "       [-0.00220862, -0.01061957,  0.01002881, ..., -0.0075301 ,\n",
      "        -0.01411539, -0.00040475],\n",
      "       ...,\n",
      "       [ 0.01010962,  0.00025196, -0.01100946, ...,  0.0098991 ,\n",
      "        -0.00487798,  0.01105472],\n",
      "       [-0.00773127, -0.00760623,  0.01052243, ..., -0.01013513,\n",
      "        -0.0092291 ,  0.00902956],\n",
      "       [ 0.00291499,  0.00083983, -0.01196923, ..., -0.00761323,\n",
      "         0.0110371 , -0.01007154]], dtype=float32)>, <tf.Variable 'fc1/bias:0' shape=(4096,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Variable 'fc2/kernel:0' shape=(4096, 4096) dtype=float32, numpy=\n",
      "array([[ 0.01446239, -0.01780149,  0.00907325, ..., -0.01770356,\n",
      "         0.0028068 ,  0.0113807 ],\n",
      "       [-0.00297545,  0.01454097,  0.01343459, ..., -0.01226447,\n",
      "        -0.01773219, -0.02546492],\n",
      "       [-0.02427764, -0.02536309, -0.01876472, ...,  0.00977865,\n",
      "        -0.01981549,  0.01919183],\n",
      "       ...,\n",
      "       [ 0.01355403, -0.01145572,  0.00726007, ...,  0.01041556,\n",
      "        -0.00507172,  0.00649354],\n",
      "       [ 0.01064842,  0.02152277, -0.02229319, ..., -0.0109983 ,\n",
      "         0.02568146,  0.02339645],\n",
      "       [-0.00981382,  0.02584123,  0.01254084, ..., -0.00103992,\n",
      "         0.02429839,  0.02414324]], dtype=float32)>, <tf.Variable 'fc2/bias:0' shape=(4096,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Variable 'predictions/kernel:0' shape=(4096, 1000) dtype=float32, numpy=\n",
      "array([[ 0.03081823, -0.00863571, -0.02569915, ..., -0.00715107,\n",
      "        -0.02022697, -0.0223019 ],\n",
      "       [ 0.0313282 ,  0.01222012, -0.03244822, ..., -0.01361095,\n",
      "         0.02981963,  0.00427499],\n",
      "       [-0.0006558 , -0.03419935, -0.01618236, ..., -0.0300859 ,\n",
      "         0.00481042,  0.01869281],\n",
      "       ...,\n",
      "       [ 0.0052763 , -0.00339944, -0.02318382, ...,  0.01549611,\n",
      "         0.0005729 , -0.03125792],\n",
      "       [-0.0315298 , -0.00669247, -0.02361757, ...,  0.00301236,\n",
      "        -0.01812585,  0.01407177],\n",
      "       [ 0.010923  ,  0.01245812,  0.03229051, ...,  0.0003753 ,\n",
      "         0.02969518, -0.01235543]], dtype=float32)>, <tf.Variable 'predictions/bias:0' shape=(1000,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "### 학습 전 기본 모델의 가중치 확인\n",
    "print(base_model.weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rollbackTarget",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
